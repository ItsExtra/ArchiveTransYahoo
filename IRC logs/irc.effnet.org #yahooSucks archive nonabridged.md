



[01:23] == Solanum [webchat@31.171.154.211] has joined #yahoosucks

[01:26] == sotty [webchat@ip4d1591ed.dynamic.kabel-deutschland.de] has quit [Ping timeout: 260 seconds]

[01:47] == testi [webchat@p4FF8225C.dip0.t-ipconnect.de] has quit [Quit: Page closed]

[01:49] == X-Scale [~ARM@31.22.160.25] has joined #yahoosucks

[02:05] == arrow22 [~arrow22@104.128.136.46] has joined #yahoosucks

[02:10] == Raccoon [~waywerd@194.34.133.208] has joined #yahoosucks

[02:10] <Raccoon> Team Yahoover!

[02:14] == DogsRNice [~DogsRNice@2600:1700:7480:95f0:24fb:1e0:e1c:3aa6] has joined #yahoosucks

[02:21] <Stiletto> done playing with the PG Offline trialware. Now I'm idling until a  canonical archiver script is solid to tackle (again) the private groups  I'm a member of.

[02:30] == pew [pew@2001:bc8:6005:19:28ed:636:a18:4382] has quit [Ping timeout: 252 seconds]

[02:37] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has quit [Ping timeout: 260 seconds]

[02:38] == DogsRNice [~DogsRNice@2600:1700:7480:95f0:24fb:1e0:e1c:3aa6] has quit [Read error: Connection reset by peer]

[02:42] == pew [pew@2001:bc8:6005:19:e533:4f0f:1851:a72d] has joined #yahoosucks

[03:01] == qw3rty2 [~qw3rty@92.116.185.161] has joined #yahoosucks

[03:06] == tech234a [uid352403@id-352403.stonehaven.irccloud.com] has joined #yahoosucks

[03:08] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has joined #yahoosucks

[03:08] == qw3rty [~qw3rty@92.116.189.5] has quit [Ping timeout: 745 seconds]

[03:11] <SketchCow> Fuckin' anyway

[03:11] <SketchCow> DO we want me to start advertising the google sheet for signing up

[03:42] == YS [webchat@172.58.87.17] has joined #yahoosucks

[03:43] == YS [webchat@172.58.87.17] has quit [Client Quit]

[03:52] == odemgi [~odemgi@200116b82c07eb001926999c7d4d1820.dip.versatel-1u1.de] has joined #yahoosucks

[03:55] == odemgi_ [~odemgi@200116b82c162200c4f8a267c2061174.dip.versatel-1u1.de] has quit [Ping timeout: 252 seconds]

[04:00] == SynMonger [~syn@64.199.84.25] has quit [Quit: Wait, what?]

[04:01] == qw3rty [~qw3rty@92.116.130.10] has joined #yahoosucks

[04:01] == SynMonger [~syn@64.199.84.25] has joined #yahoosucks

[04:10] == asdf_ [webchat@c-24-21-236-69.hsd1.or.comcast.net] has joined #yahoosucks

[04:10] == qw3rty2 [~qw3rty@92.116.185.161] has quit [Ping timeout: 745 seconds]

[04:13] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has quit [Ping timeout: 260 seconds]

[04:27] == asdf_ [webchat@c-24-21-236-69.hsd1.or.comcast.net] has quit [Ping timeout: 260 seconds]

[04:36] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has joined #yahoosucks

[04:46] == odemgi [~odemgi@200116b82c07eb001926999c7d4d1820.dip.versatel-1u1.de] has quit [Ping timeout: 252 seconds]

[04:48] == odemgi [~odemgi@200116b82c07eb001926999c7d4d1820.dip.versatel-1u1.de] has joined #yahoosucks

[04:49] == odemgi [~odemgi@200116b82c07eb001926999c7d4d1820.dip.versatel-1u1.de] has quit [Remote host closed the connection]

[05:07] == manjaro-u [~manjaro-u@kti.a12.18.ktis.net] has quit [Konversation terminated!]

[05:16] == tech234a [uid352403@id-352403.stonehaven.irccloud.com] has quit [Quit: Connection closed for inactivity]

[05:17] == arrow-22 [~arrow22@104.128.136.46] has joined #yahoosucks

[05:21] == arrow-22 [~arrow22@104.128.136.46] has quit [Client Quit]

[05:26] == arrow22 [~arrow22@104.128.136.46] has quit [Ping timeout: 612 seconds]

[05:47] == mode/#yahoosucks [+o SketchCow] by PurpleSym

[05:50] == W_1 [webchat@x-134-84-102-191.reshalls.umn.edu] has joined #yahoosucks

[05:58] == satoshi [~serv@201.131.87.128.wireless.tknet-ti.com.br] has joined #yahoosucks

[06:00] <satoshi> how is the archiving going on? is the bot able to join plubic groups and save everything?

[06:00] <satoshi> public

[06:08] == isiah [webchat@cpe-184-54-77-18.swo.res.rr.com] has quit [Ping timeout: 260 seconds]

[06:29] == W_1 [webchat@x-134-84-102-191.reshalls.umn.edu] has quit [Ping timeout: 260 seconds]

[06:53] == odemgi [~odemgi@200116b82c07eb001926999c7d4d1820.dip.versatel-1u1.de] has joined #yahoosucks

[07:13] == teststsas [~akovaski@99-12-190-228.lightspeed.milwwi.sbcglobal.net] has quit [Read error: Operation timed out]

[07:50] == JAA [~JAA@144.217.81.131] has quit [Read error: Operation timed out]

[07:50] == kiska2 [james@216.21.8.63] has quit [Read error: Operation timed out]

[07:51] == dxrt [~dxrt@209.141.42.18] has quit [ZNC - http://znc.sourceforge.net]

[07:51] == dxrt [~dxrt@209.141.42.18] has joined #yahoosucks

[07:52] == mode/#yahoosucks [+o dxrt] by Fusl

[07:53] == kiska2 [james@216.21.8.63] has joined #yahoosucks

[07:53] == mode/#yahoosucks [+o kiska2] by Fusl

[07:54] == JAA [~JAA@131.ip-144-217-81.net] has joined #yahoosucks

[07:54] == mode/#yahoosucks [+o JAA] by AlsoJAA3

[07:55] == mode/#yahoosucks [+o JAA] by Fusl

[08:21] <@betamax> satoshi: hi! unfortunately all attempts to make an auto-joining bot haven't worked

[08:22] <@betamax> Yahoo's anti-abuse systems are just too effective

[08:22] <@betamax> :(

[08:23] <@betamax> however work is being done on a manual system with some automation

[08:23] <@betamax> ie: each group must be joined manually by a person, but the group to  join and the archiving of said groups will be automatic

[08:24] <@betamax> once that's up and running you'll see me begging on this channel for  people to spend time manually completing captchas to join groups :)

[08:28] <@PurpleSym> betamax: Do you have examples for the captchas theyâ€™re using? Maybe we can break them?

[08:30] <@betamax> it's google "I am not a robot", so it's probably not going to be possible

[08:31] <@betamax> and subscribing to groups via email (which doesn't need a captcha)  doesn't work either, as you get blocked* after around 5 signups, even if you wait 30 mins between each one

[08:31] <@betamax> however, by manually completing captcha's, you can get through one every 5-10 seconds or so

[08:32] <@betamax> which is much faster than any of the automated methods I tried

[08:32] <teovall> have you looked at the API for files yet? i can't figure out how to get into folders

[08:32] <@PurpleSym> Ah yeah, recaptcha is not going to be possible for us to break.

[08:33] <@betamax> teovall: have you tried https://github.com/nsapa/yahoo-group-archiver/ ?

[08:33] <teovall> for files, yahoo-groups-backup scrapes the HTML, but i'm having trouble getting it working because i can't tell when its done loading  everything through AJAX

[08:33] <@betamax> it claims to support the files, and (thanks to the great worok by nico_32_ ) basically everything else

[08:34] <@betamax> teovall: nico_32_ managed to work out how to get into folders for the links

[08:34] <@betamax> perhaps it is the same for files?

[08:35] <teovall> ohh... ok... thx

[08:37] <thuban1> folders and events endpoints should be added to the wiki page, along with groups that use them, for testing purposes

[08:38] <@betamax> the events endpoint is... interesting

[08:39] <@betamax> it's Yahoo calendar, but using data from the groups API in the GET request

[08:39] <thuban1> that... makes sense? i mean, in context

[08:39] <thuban1> anyway i'm about to go to sleep but i can comb through logs / nsapa's  fork for urls tomorrow if nobody gets to it before then

[08:40] <@betamax> I know of https://groups.yahoo.com/neo/groups/kokun_events

[08:40] <@betamax> that's a good one for events

[08:42] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has quit [Ping timeout: 260 seconds]

[08:44] <thuban1> teovall: d'you have a example of a group that stores files in folders?

[08:44] <teovall> its not a public group

[08:45] <thuban1> better a private one than nothing, at least until somebody finds a public one

[08:49] <teovall> ahh.. found it... https://groups.yahoo.com/api/v2/groups/[group]/files/?sfpath=[pathURI]

[08:51] <teovall> i don't know if i should bother to keep working on yahoo-groups-backup  though since momentum seems to be converging on other scripts

[08:52] <@betamax> really? it's the one that I think is the best right now

[08:52] <teovall> AFAIK though its the only one that supports building a static HTML site from the scraped data

[08:52] <@betamax> all it needs is polls and it will have everything

[08:53] <@betamax> which other ones do you think have more momentum

[08:53] <@betamax> ?

[08:53] <teovall> do you mean yahoo-group-archiver or yahoo-groups-backup (all these names are horrible btw)

[08:53] <@betamax> ooops!

[08:54] <teovall> i've been working on yahoo-groups-backup and it only has messages and (broken) files

[08:54] <@betamax> to clarify: I was talking about yahoo-group-archiver

[08:54] <@betamax> sorry, forgot there was another similarly-named one

[08:54] <teovall> ok

[08:56] <teovall> you're working on YahooGroups-Archiver though, aren't you?

[08:57] <@betamax> teovall: I *think* the yahoo-group-archiver one supports files in folders using the JSON api

[08:57] <teovall> yes, yahoo-group-archiver, does seem to

[08:58] <@betamax> all it needs now is polls, and we'll have a canonical script

[08:59] <teovall> this is such a mess... there's so much duplicated effort

[08:59] <@betamax> yes, there is

[08:59] <@betamax> I am going to remove my script (YahooGroups-Archiver) from the wiki

[09:00] <teovall> even within yahoo-group-archiver there's two separate forks that are being concurrently developed

[09:00] <teovall> nsapa and Frankkkkk

[09:02] <@betamax> ugh, it is a pain

[09:02] <thuban1> link to frankkkkk's? (relevant features?)

[09:04] <@betamax> frankkkkk's incorporates changes from dairiki, which mostly are error-handling bugfixes

[09:04] <@betamax> view the tree of mess: https://github.com/nsapa/yahoo-group-archiver/network/members

[09:08] <thuban1> doesn't look *too* unmergeable

[09:09] <@betamax> since nico_32_ is active in this channel I am inclined to merge everything into that one

[09:24] <teovall> we should make sure to save metadata as well as just data... files for  instance it looks to only be saving the files themselves, losing the  description, owner, and creation time

[09:25] <@betamax> I'm getting a "fileinfo.json" file saved along with the files

[09:25] <@betamax> that seems to be the metadata

[09:25] <teovall> oh ok... i've just been looking at the code not running it

[09:26] <teovall> oh... i see where that's saved

[09:26] <teovall> that's good

[09:26] <@betamax> I see it also strips the JSON from the message to give a raw .eml file

[09:27] <@betamax> I think(?) you're not losing anything there, as all the other metadata  in the JSON is derived from the raw email, but I'm not sure

[09:28] <@betamax> do any of the other scripts support polls?

[09:28] <@betamax> cause I am not sure if there is a JSON api for them

[09:28] <@betamax> group will poll if anyone wants to investigate:

[09:28] <@betamax> https://groups.yahoo.com/neo/groups/relationship-poll/info

[09:29] <teovall> i hate to see too much processing being done on stuff... the archive  should be as raw as possible... that raw data can always be massaged for presentation later

[09:30] <@betamax> I agree

[09:30] <@betamax> do you think it is a trivial matter to make it not extract the raw eml and just give the JSON ?

[09:30] <@JAA> betamax, PurpleSym: Actually, there does seem to be a way to break  reCAPTCHA through the audio challenge and speech recognition. Someone  linked a Firefox addon for this recently, which requires you to click  the "I'm not a robot" checkbox and then another button in the challenge  (and funnily enough uses Google's speech recognition to break the  captcha, among some other services), but it should be possible 

[09:30] <@JAA> to automate that.

[09:31] <@JAA> This isn't a "we can do that in an hour or two" thing though.

[09:31] <@betamax> link? I'm curious how reliable this would be

[09:31] <@JAA> I haven't tried it myself, but others said it was quite reliable. Trying to find it again.

[09:32] <@JAA> https://github.com/dessant/buster

[09:32] <@betamax> teovall: by default, yahoo-group-archiver tries to recombine the emails with attachments, but you can turn it of with a flag

[09:34] <teovall> it looks like it should be pretty simple to just save the raw json instead of .eml

[09:34] <teovall> could even just save both

[09:34] <@betamax> I'd go for just the json

[09:35] <@betamax> we'll have to store all this stuff at some point, and duplication is to be avoided :)

[09:35] <teovall> stuff like this worries me... cause doing stuff half way is worse than not at all... https://github.com/nsapa/yahoo-group-archiver/blob/master/yahoo.py#L24

[09:36] <teovall> cause that's definitely not the right way to unescape character entities... and that's definitely not all of them

[09:37] <teovall> and then you're left with partially escaped and partially unescaped

[09:39] <@betamax> teovall: the sad truth is we're going to make mistakes, we're going to lose data, we're going to get corrupted data

[09:39] <@betamax> we're going to corrupt data outselves

[09:39] <@betamax> but if it works 95% of the time, it's probably good enough

[09:39] <thuban1> teovall: iirc the unescape being used here is janky because not intended for html: https://docs.python.org/2/library/xml.sax.utils.html

[09:39] <thuban1> python 3 does this with html.unescape

[09:40] <@betamax> however, if you'd like to fix that then I'm sure nico_32_ would love a PR

[09:40] <thuban1> python 2 i think has HtmlParser.unescape?

[09:41] <@betamax> JAA: OH GOODNESS IT WORKS, IT SOLVES THE CAPTCHA'S

[09:41] <@betamax> .... this is amazing

[09:41] <teovall> well, it should only unescape things that it needs to parse to gather  all the data... but its unescaping some of the data that it's saving

[09:41] <thuban1> ah yeah

[09:44] <@JAA> :-)

[09:45] <Igloo> Yes, I've used it before

[09:46] <thuban1> teovall: idk, i think it seems reasonable to unescape filenames for folders/photos/etc

[09:47] <thuban1> agree the messages themselves might be problematic (is the 'raw' encode error relevant to this?)

[09:48] <teovall> hmm... yeah, i think the only place its used on actual data is for messages

[09:48] <teovall> https://github.com/nsapa/yahoo-group-archiver/blob/master/yahoo.py#L71

[09:48] <teovall> and if we just save the raw json that won't be a problem

[09:48] <@betamax> JAA: darn, it's blocked me

[09:48] <teovall> and if everywhere else the unescaped metadata is saved somewhere

[09:49] <@betamax> "Your computer or network may be sending automated queries. To protect  our users, we can't process your request right now. For more details  visit our help page"

[09:49] <@JAA> betamax: I'm not surprised. Probably still needs a lot of IPs.

[09:51] <@betamax> yup, switching IP and it works again

[09:51] <@betamax> I'm not clued up on this, but is there a way to get a large chunk of IPs and switch between them every 2 minutes or so?

[09:52] <teovall> i don't think so.... not without money or connections at an ISP

[09:52] <@betamax> (perhaps Fusl knows about this?)

[09:53] <thuban1> teovall: actually, we shouldn't be exclusively using the /raw endpoint at all, given encoding problems

[09:53] <thuban1> https://yahoo.uservoice.com/forums/209451-us-groups/suggestions/9644478-displaying-raw-messages-is-not-8-bit-clean

[09:55] <@betamax> is there a good alternative, though?

[09:55] <thuban1> yes

[09:55] <thuban1> hit /as well as /raw and grab ygData.messageBody

[09:55] <thuban1> */ as

[09:56] <thuban1> (cf https://groups.yahoo.com/api/v1/groups/cienciaficcion/messages/89704/raw vs https://groups.yahoo.com/api/v1/groups/cienciaficcion/messages/89704/)

[09:56] <@betamax> that'll basically double the time needed to archive a group

[09:57] <@betamax> as well as halve the time before you get blocked

[09:57] <@betamax> so it would be awesome if you could add that in to yahoo-group-archiver

[09:57] <@betamax> but please add a flag to disable that behaviour if you do

[09:58] <thuban1> aye

[09:59] <Igloo> Use IPv6

[09:59] <Igloo> :P

[10:00] <teovall> ok... so with firefox, if i save the json file from the /raw endpoint and open it in a hex editor, the characters are there

[10:00] <@betamax> that's kinda what I was wondering

[10:00] <@betamax> (the IPv6 thing)

[10:00] <teovall> if you copy and paste it out of firefox though... they're just replaced with NULL

[10:01] <@betamax> I saw Fusl mentioning something about IPv6 blocks to get around Yahoo's rate limiting

[10:01] <@betamax> would this work with reCaptcha?

[10:02] <teovall> i'm pretty sure the /raw endpoint is correct... it needs to be mime  decoded to be presentable, but i think the data is there and correct

[10:02] <thuban1> teovall: oh, huh. well that works then

[10:07] <@PurpleSym> teovall: It is not. Every broken character is encoded as EF BF BD,  which decodes to U+fffd, which is the unicode replacement character  (question mark).

[10:10] <teovall> hmm

[10:12] <teovall> oof... you're right... gross

[10:13] <teovall> what yahoo did is gross, not that you're right

[10:13] <@PurpleSym> Itâ€™s ok.

[10:16] <thuban1> question from a member of the public: "Is there anyone making a list of groups with AWOL/dead admins, or is that just going to have to be word  of mouth for people looking for those fics from now on?"

[10:16] <teovall> i wouldn't want to lose the data in the email headers... but losing all non-ASCII characters is far worse

[10:17] <thuban1> is it safe to host a _list_ of such groups on eg the archiveteam wiki  page, or should i suggest people coordinate somewhere else?

[10:21] <teovall> so yeah, to get a full archive would mean hitting both endpoints

[10:22] <@betamax> thuban1: I see no problem with a lsit

[10:22] <@betamax> *list

[10:22] <@betamax> in fact, with that way, we can draw attention to it

[10:23] <@betamax> "hey people, we have a list of groups here, anyone know the admin of any of these?"

[10:23] <@betamax> go for it

[10:23] <thuban1> okay. i'm going to give the wiki page a quick facelift so i can start directing people to it

[10:35] <@betamax> JAA: re grabbing of group front pages, that's good to know

[10:36] <@betamax> I suspect I'll have to take two approaches

[10:36] <@betamax> a) an archivebot grab to get all the CSS / JS / IMG for the wayback

[10:36] <@betamax> b) an HTML-only fast-as-you-can grab to get the info needed to determine which groups should be prioritized

[10:37] <@JAA> Yeah, sounds reasonable.

[10:39] <@JAA> By the way, the reason why qwarc can only really do b) is that it  doesn't do any HTML parsing. That's normally what eats a lot of CPU time in wpull.

[10:39] <@JAA> It's basically just a dumb "fetch and store to WARC" tool which you have to tell *exactly* what to retrieve.

[10:40] <@JAA> Instead of HTML parsing, I use str.index and sometimes regex to extract the information needed to fetch the other things.

[10:40] <@betamax> that will probably work in this case

[10:41] <@betamax> I still have no idea exactly how we should be priorisising groups

[10:41] <@betamax> are oldest more important?

[10:41] <@betamax> ones with the most members? the most messages?

[10:41] <@JAA> Probably a mixture of all of these.

[10:42] <@betamax> a lot of groups filled up with spam after they became inactive, do we  ignore the ones with little activity, then no activity, then lots of  activity?

[10:42] <@betamax> and so on...

[10:42] <@betamax> I don't feel particularly qualified to make these decisions

[10:43] <@betamax> and of course, this doesn't consider public groups

[10:43] <@betamax> which could have photos / files / databases / links

[10:43] <@betamax> do we search group descriptions / names for keywords which could indicate lots of photos / files ?

[10:43] <@betamax> etc.....

[10:54] <@PurpleSym> Imo you should prioritize the groups I did not grab plus HTML/files/galleries/â€¦

[10:55] <@PurpleSym> And I would prioritize early messages, since there was an uprise in spam around 2013/2014.

[10:56] <@betamax> what about pseudo-private groups? did you attempt to archive any of them?

[10:56] <@PurpleSym> Nope, public only.

[10:57] <@betamax> do you have a list of all the groups you grabbed?

[11:00] <@PurpleSym> Hm, not sure. That big JSON file includes private groups.

[11:00] <@betamax> how did you consider a group "public"

[11:01] <@betamax> (I should really check the fields in the JSON file you sent me before wasting your time. Sorry)

[11:01] <@PurpleSym> I did not use metadata for that. The script just tried to fetch messages and if it failed it moved on, I think.

[11:01] <@PurpleSym> But let me checkâ€¦

[11:03] <@PurpleSym> Yes, it simply skipped the group if a code 1101, 1203 or 2102 error was received.

[11:04] <@betamax> Ah, OK

[11:32] == testi [webchat@p4FF8225C.dip0.t-ipconnect.de] has joined #yahoosucks

[11:35] <@PurpleSym> I could probably compile a list of groups which I have zero messages  for, if thatâ€™s useful. But itâ€™s going to take some time (again).

[11:40] <@betamax> I'd wait for now

[11:40] <@betamax> until a clearer strategy is apparent

[11:42] <@betamax> right now, SketchCow tweeting the link to the form is bringing in responses

[11:43] <@betamax> 144 responses so far - we'll focus on these first

[11:43] <@betamax> https://tinyurl.com/savegroupsresults

[11:53] == phillipsj [~phillipsj@107-190-70-146.cpe.teksavvy.com] has joined #yahoosucks

[11:59] <@markedL> what kind of group does the email join work on? 

[12:01] <@betamax> technically all groups

[12:02] <@betamax> but you get blocked pretty quickly (ie: after 5 or so groups)

[12:02] <@betamax> and with admin-approval ones, you have to email back and explain why you want to join

[12:16] <phillipsj> so catch-all addressess of the form yahoo2MDD@domain then?

[12:18]  * phillipsj used https://www.grc.com/x/ne.dll?rgyemqde (https://www.grc.com/ppp.htm with a custom charater set)

[12:18] <@betamax> It's <groupname>-subscribe@yahoogroups.com

[12:18] <@markedL> I think he's saying we have infinite email addresses available, if you're saying we don't need a yahoo account 

[12:18] <@betamax> even if a non-english group, the .com still works

[12:18] <@betamax> wait, no we need a yahoo acount

[12:19] <@betamax> *account

[12:19] <phillipsj> oh, that sucks.

[12:19] <@betamax> because otherwise, even though you get sent new messages sent to the group

[12:19] <@betamax> you cannot login to the web interface and so cannot archive all existing data

[12:22] <@markedL> ok, that part is clear, need a yahoo account. I can think 3 of not so great but better than nothing methods for recaptcha bypass.

[12:23] <@markedL> but if the signup is the hardest part, maybe what's simplest is using  people's existing group memberships, then instead the focus is on making something that people can run on their own accounts 

[12:25] == Feathers [webchat@host-79-78-223-181.static.as9105.net] has joined #yahoosucks

[12:29] <tapedrive> ive been working on an idea betamax had

[12:30] == Feathers [webchat@host-79-78-223-181.static.as9105.net] has quit [Ping timeout: 260 seconds]

[12:30] <@PurpleSym> Also to whoever is using mongodb here (yahoo-groups-backup): Donâ€™t. I tried that and it simply does not work.

[12:30] <@PurpleSym> (Well, not with 2 billion messages at least)

[12:31] <tapedrive> essentially think of the warrior, but for group signups, and where you need people solving captchas

[12:32] <tapedrive> its curently a tracker with a mysql db, and a chrome extension that  gets groups from there, and loads them in the page. user solves captcha, and process repeats

[12:33] <tapedrive> the thinjing is that if jason can get people to test thousands of  archive.org games/emulators, maybe we can get some peolle to solce  captchas

[12:35] <@markedL> so the 3 methods I know of for recaptcha, is distributing to humans,  using google cookies with long term history, and using the audio  recognition api's ( https://duckduckgo.com/?q=audio+recaptcha+bypass+github&t=canonical&ia=web )

[12:39] <tapedrive> can you explain "google cookies with long term histoey" a bit more?

[12:41] == mode/#yahoosucks [+o tapedrive] by betamax

[12:42] <@markedL> I'm going to paste a link so we can read the primary sources on it https://en.wikipedia.org/wiki/ReCAPTCHA#No_CAPTCHA_reCAPTCHA

[12:45] <@betamax> the issue with that is that mass-signups is pretty bot-like

[12:45] <@betamax> and therefore regardless of what "good" history you had previously,  after a certain number of joins you'll get the difficult captcha

[12:46] <@betamax> and therefore you'll need someone monitoring it

[12:46] <@betamax> meaning you might as well just have someone manually complete them in the first place

[12:50] <@markedL> I don't think anything with human involvement on our side is the easiest option. Some human involvement should be "outsourced" to the group admins or group members 

[12:52] <@betamax> I don't see any way to do it without human involvement on our side

[12:54] <@markedL> I'd propose, we build a desktop app that works on win/mac/linux, asks  for a yahoo username/password or finds a cookie in a cookie jar, runs a  crawl on their computer/network connection, and rsync or posts it to us  if they choose to an option 

[12:54] <@betamax> define "run a craw"

[12:55] <@betamax> because we already have yahoo-group-archiver

[12:55] <@betamax> which archives private groups but doesn't send them to us

[12:56] <@markedL> yes, building upon what already exists/most tested, makes it low risk and faster start 

[12:57] <@betamax> this still doesn't solve the problem of the millions of groups that  people aren't going to be members of, that are going to be lost

[12:57] <@betamax> I'm not saying we're going to get all of them, far from it

[12:58] <@betamax> but this would be - no *is* (it works) - a way to target high priority groups that would otherwise be lost

[12:59] <@markedL> the warrior project is going to get all public groups

[13:00] <@betamax> all *messages* on public groups

[13:00] <@betamax> not the files / photos / attachments / polls / calendars / links

[13:09] <@markedL> you ideally want to join all public groups, to get those additional types of data

[13:09] <@betamax> of course

[13:10] <@betamax> as well as joining all the groups that require you to be a member to  view messages, but don't require an admin to approve new member joins

[13:10] <@betamax> having people join as many groups as possible is the only was I can see to do this

[13:27] <@markedL> that's fine as an idealized goal, my input is just, don't put anything difficult in the critical path. like 3 milestones. Release something that runs on user accounts, and maybe self updates. Encourage humans to join unrepresented high priority groups. Allow drop in replacement of human's account as automated accounts improves/allows. 

[13:31] <@betamax> "Encourage humans to join unrepresented high priority groups. Allow drop in replacement of human's account"

[13:32] <@betamax> ^^ that is basically what the system I devised with tapedrive is

[13:32] <@betamax> with the addition of coordination, so that we don't get everyone joining the top 10 high priority groups

[13:33] <@betamax> literally, add the chrome extension, then it'll take you the homepage of a high priority group that hasn't been saved yet

[13:34] <@betamax> you join that one, the chrome extension detects this and gives you another

[13:34] <@betamax> and so on

[13:37] == vole-dev [~akovaski@99-12-190-228.lightspeed.milwwi.sbcglobal.net] has joined #yahoosucks

[13:38] <@markedL> sure, I didn't mean to steal your idea as much as understand how it fits in a timeline, the channel is hard to keep up with

[13:44] <@betamax> no, thanks for the feedback

[13:44] <@betamax> I admit I am nervous that we devised this whole system and I am realistically not sure if anyone will use it

[13:45] <@betamax> as I'm not sure how likely it is to expect that people provide manual help

[13:46] <@betamax> warriors, sure, but manually joining groups over and over? it is probably a big ask

[13:46] <@tapedrive> You actually can join them quite fast

[13:46] <@tapedrive> During testing I was managing to join 2 every 10 seconds

[13:47] <@betamax> ooh, that's twice as fast as I was expecting

[13:48] <@betamax> PurpleSym: how is the new discovery coming along? any rough ETA?

[13:54] <@PurpleSym> 2813657 discovered, still 400k search terms in queue.

[13:55] <@betamax> any idea how many terms were in the search queue to begin with?

[13:55] <@betamax> because that seems to be more than your previous grab already, which is good

[13:56] <@PurpleSym> No, itâ€™s incremental. Whenever search returns more than 500 results I  add a letter to the search term and add it to the queue.

[13:58] <@betamax> that is really quite clever

[13:58] <@PurpleSym> Heh, no, itâ€™s computer science 101 ;)

[14:11] <@betamax> PurpleSym: when does your discovery script get the group info API ?

[14:11] <@betamax> is that done as it discovers them, or does it do that later?

[14:13] <@PurpleSym> It doesnâ€™t. That would be the 2nd step. I only save whatâ€™s returned by search.

[14:13] <@PurpleSym> Which is similar to info, but lacks a few fields.

[14:15] <@betamax> I don't suppose it has the https://6xq.net/paste/yahoo-groups-info.json.lz

[14:15] <@betamax> oops, not that

[14:16] <@betamax> the groupVis / memberVis / messageVis / etc... fields ?

[14:17] <@PurpleSym> It has:  ["adult","desc","flagBits","groupId","groupUrl","intlCode","lastPosted","members","messageVis","name","nameWithHighlightedText","order","restricted","title"]

[14:20] <@betamax> I think messageVis and restricted might be enough for what I need

[14:20] <@betamax> I will investigate, thanks

[14:21] <@PurpleSym> Yeah, if you want to know which groupsâ€™s archives can be accessed without joining, these are the important flags.

[14:22] <@betamax> lastPosted and members will be useful for prioritising groups as well

[14:39] == odemgi [~odemgi@200116b82c07eb001926999c7d4d1820.dip.versatel-1u1.de] has quit [Quit: Leaving]

[14:39] == odemgi [~odemgi@200116b82c07eb001926999c7d4d1820.dip.versatel-1u1.de] has joined #yahoosucks

[14:39] <odemgi> .

[14:39] == odemgi [~odemgi@200116b82c07eb001926999c7d4d1820.dip.versatel-1u1.de] has quit [Client Quit]

[14:40] == odemgi [~odemgi@2001:16b8:2c07:eb00:1926:999c:7d4d:1820] has joined #yahoosucks

[14:41] == Kirkman [webchat@97-85-178-47.static.stls.mo.charter.com] has joined #yahoosucks

[14:47] <nico_32_> hello again

[14:48] == Kirkman [webchat@97-85-178-47.static.stls.mo.charter.com] has quit [Ping timeout: 260 seconds]

[14:50]  * betamax waves

[14:59] <@betamax> nico_32_: fantastic work on yahoo-group-archiver, btw

[14:59] <@betamax> it's almost ready to be used as our canonical archiving script for non-public groups

[15:01] <nico_32_> it need someone with python experience to go over the code

[15:01] <@betamax> I took a look to see how possible it would be for polls to be added, and I couldn't find a JSON api

[15:01] <@betamax> so maybe we'll have to go without polls

[15:02] <nico_32_> https://groups.yahoo.com/api/v1/groups/tokra-resistance/polls?count=100 => "surveyId": 13081520 => https://groups.yahoo.com/api/v1/groups/tokra-resistance/polls/13081520

[15:03] <nico_32_> i don't know if we can get every poll

[15:04] <nico_32_> we don't get the total number of poll

[15:05] <@betamax> wow, I completely missed that API

[15:06] <nico_32_> we get the vote of every members

[15:06] <nico_32_> that can be an issue

[15:06] <@betamax> do we? I'm looking at a poll and can't get any info about the votes

[15:07] <@betamax> if some polls do indeed give the results of every member, can you see  if you also get that info if you go through the web UI

[15:07] <@betamax> because if it is accessable through the web UI, then it is not really a problem

[15:08] <nico_32_> https://pastebin.com/h48jwazn

[15:09] <@PurpleSym> nico_32_: Whereâ€™s the code?

[15:09] <nico_32_> PurpleSym: https://github.com/nsapa/yahoo-group-archiver/ ?

[15:10] <@betamax> nico_32_: oh, right. That.... could be an issue

[15:11] <nico_32_> probably should overwrite the 'responses' array 

[15:14] <@betamax> I'm not even sure we should be downloading that, tbh

[15:15] <@betamax> particularly with the email addresses, it could be seen as data-harvesting

[15:15] <@PurpleSym> nico_32_: Iâ€™m not sure itâ€™s a good idea to forcefully encode rawEmail into latin1.

[15:15] <@betamax> my initial thought would just be to get the polls?count=100

[15:16] <@betamax> but then a poll without the data isn't very useful :\

[15:16] <nico_32_> yeah

[15:17] <@PurpleSym> Also /raw returns some headers which have been scrubbed from the raw  email data. You could add them, so threading information is preserved.

[15:17] <@betamax> JAA, Fusl, Kaz, kiska2, PurpleSym, SketchCow: ^^^ (re: polls)

[15:18] <@betamax> should we grab polls that could contain personal info

[15:18] <@PurpleSym> nico_32_: Hereâ€™s a script I wrote some time ago: https://6xq.net/paste/tombox.py

[15:18] <@betamax> note that polls require you to be a member of the group, so the info,  while "publicly accessible", as anyone can join, isn't immediately  piblic

[15:19] <@PurpleSym> Actually, itâ€™s on github: https://github.com/PromyLOPh/yg2mbox

[15:19] <nico_32_> i think i should just download the attached files + dump the whole raw json

[15:20] <@PurpleSym> Probably better to do conversion to mbox in postprocessing, yes.

[15:20] <nico_32_> eml are nice for enduser

[15:20] <@betamax> PurpleSym: alternatively, if we grab the whole JSON, will we have everything to add in the headers at a later date

[15:20] <nico_32_> but the project is changing its goal

[15:20] <@betamax> nico_32_: if you are willing, I would definitely add polls into the script

[15:21] <@betamax> but we'll need to change how the flags work so you can selectively enable things

[15:21] == DogsRNice [~DogsRNice@2600:1700:7480:95f0:646f:ba30:bd1:dc1a] has joined #yahoosucks

[15:21] <@betamax> e.g: I want messages, photos and polls

[15:22] <nico_32_> it should already lets you download only photos and links

[15:22] == testi [webchat@p4FF8225C.dip0.t-ipconnect.de] has quit [Ping timeout: 260 seconds]

[15:22] <@betamax> rather than making a flag download something, can we make it *not* download the thing

[15:22] <nico_32_> -l -c tokra-resistance

[15:22] <nico_32_> logging in...

[15:23] <nico_32_> * Written 54 links from root folder

[15:23] <nico_32_> * Getting events between 20010130 and 20031027

[15:23] <nico_32_> yes it work

[15:24] <@betamax> so if you run it with no flags it gets everything, and you can then choose if you don't want something

[15:24] <nico_32_> ha

[15:26] <nico_32_> the way it work currently make it easy to add additionnal things

[15:28] <nico_32_> hu remplace store_true by store_false, change the description

[15:28] <nico_32_> and it should do what you want

[15:29] <@betamax> the error handling on the script needs a little tweaking, as well

[15:30] <@betamax> for unknown reasons (thanks Yahoo) there are occasions when the API gives you a 500 error

[15:30] <@betamax> ie: request message 811: fine, 812: 500 error, 813: fine

[15:31] <@betamax> I have only experienced this with messages, but it is entirely possible that Yahoo are broken in other places

[15:31] <@betamax> it is a shame that all the "s.get()" in the script are spread out

[15:31] <@betamax> makes it a bit more difficult to handle this

[15:35] <nico_32_> it use def yga.get_file & yga.download_file everywhere

[15:36] <@betamax> in this case (a message) it as get_json

[15:37] <@betamax> *was

[15:39] <@JAA> betamax: If the publicity of the data is obvious to the users, then I  don't have a problem with it. If it's not exposed in the web interface  or hidden somewhere unintuitive etc., then I'd say we should probably  skip it. And just in case, because the idea often gets thrown around  with things like this: no, rewriting the responses isn't happening, at  least in WARCs. If you want to create an independent dump 

[15:39] <@JAA> of the data in some reasonable format that could e.g. be the base for launching a mirror site, then do whatever.

[15:41] <@betamax> JAA: yes, that's what I thought

[15:42] <@betamax> although I'm not sure that these would have been WARC'd anyway, because you need cookies to get them and nico_32_'s script

[15:43] <@JAA> Anything HTTP can be WARCd in general. :-)

[15:43] <@JAA> Whether it's a good idea and whether the WBM will play it back is another question of course.

[15:44] == jOnAS88 [webchat@89.179.15.109.rev.sfr.net] has joined #yahoosucks

[15:44] <@betamax> I wonder if there's a way we can hack requests (python) to write a WARC every time it gets something

[15:44] <@JAA> Oh dear

[15:44] == thuban1 [~weechat@c-73-211-96-74.hsd1.il.comcast.net] has quit [Read error: Connection reset by peer]

[15:44] <@JAA> I did that with aiohttp, and it wasn't pleasant.

[15:45] <@JAA> It's probably easier to use a MITM proxy, e.g. warcprox.

[15:45] <@betamax> I mean, realistically, this isn't going in wayback

[15:45] <@betamax> seeing as you need to be logged in with cookies to get it

[15:45] <@betamax> so probably just getting the raw data is fine

[15:45] == thuban1 [~weechat@c-73-211-96-74.hsd1.il.comcast.net] has joined #yahoosucks

[15:45] <jOnAS88> OR MAYBE A YAHOO GROUÂ¨PS EMULATOR IN THE FUTURE

[15:45] <jOnAS88> sorry

[15:45] <jOnAS88> caps

[15:46] <@JAA> I mean, as long as it writes the correct data, sure.

[15:46] <@JAA> And it can certainly be done with requests.

[15:46] <@JAA> But whatever it is, it must preserve the actual data sent over the  wire, not something with transfer encoding removed, headers normalised,  or things like that.

[15:46] <@JAA> And that's the part that gets quite tricky to hack into these libraries.

[15:47] == jOnAS88 [webchat@89.179.15.109.rev.sfr.net] has quit [Client Quit]

[15:47] == Jonas____ [webchat@89.179.15.109.rev.sfr.net] has joined #yahoosucks

[15:47] <@JAA> At least in the case of aiohttp, it meant monkey-patching private APIs, for example.

[15:47] <Jonas____> hello everybody

[15:56] <Jonas____> I'm getting HTTP 500 errors with up to date https://github.com/andrewferguson/YahooGroups-Archiver script for some groups (other are fine and I can see the stuck pages  with my browser). Is there any script that bypass this fake HTTP 500  error ? cheers

[15:57] <@betamax> ah, that's my script

[15:58] <@betamax> fyi: most effort is now on a different script, that can get files, photos, etc.. as well as messages

[15:58] <@betamax> however, bypassing a single 500 error is easy

[15:58] == girst [~girst@170.130.142.228] has quit [Quit: ZNC 1.7.3 - https://znc.in]

[15:58] <@betamax> say it is getting stuck on message 512

[15:58] <@betamax> just make a new file in the <groupname> folder called "512.json"

[15:59] <@betamax> run the script again, it will see this file and think it has already got that message, so will skip it

[16:01] <nico_32_> tiny update on nsapa/yahoo-group-archiver

[16:01] == girst [~girst@170.130.142.228] has joined #yahoosucks

[16:07] == tech234a [uid352403@id-352403.stonehaven.irccloud.com] has joined #yahoosucks

[16:29] == Lord_Nigh [Lord_Nigh@pool-108-52-174-156.phlapa.fios.verizon.net] has joined #yahoosucks

[16:30] <Lord_Nigh> I have access to a few restricted/private yahoo groups which imho need  archiving. other than manually contacting the group admins, is there  anything i can do?

[16:35] == testi [webchat@p4FF8225C.dip0.t-ipconnect.de] has joined #yahoosucks

[16:38] <Lord_Nigh> the restricted groups I have access to are: "catweasel" "Catweasel-Dev" "dungeon_tiles" "DX_Files"(private) "ET-3400" "gbdev" "msx-scc"  "OldDosOrcad" "oxyd" "speakjet" "the-linear-users-group" "UCSDPascal"  "yamahablackboxes" "YamahaDX" "YamahaDXfiles"

[16:38] <Lord_Nigh> everything else i'm subscribed to is public so i fed it to the form

[16:40] <Lord_Nigh> once I get back to my main computer, if there's a downloader utility, I'd be happy to at least locally archive those groups

[16:40] <Lord_Nigh> balrog: you know more about this, right?

[16:44] <Lord_Nigh> maybe we can get philpem to chime in, since his fork is the basis of the two main yahoo archiver forks

[16:45] <Lord_Nigh> which seem to have diverged a bit; one grabs more cookies and has  better retry support, the other correctly stores the last modified time  for everything

[16:45] == ephemer0l [~ephemer0l@all-is.organizedmagnetism.com] has joined #yahoosucks

[16:45] <Lord_Nigh> and the other one also stores databases and calendars properly

[16:47] <teovall> if someone can merge everything together so we have one canonical fork, i'd be more likely to contribute improvements and fixes

[16:47] <Lord_Nigh> i just poked philpem in a private message, we'll see what happens

[16:47] <Lord_Nigh> if he can cherry pick or merge in the changes of the two divergent forks...

[16:49] <vole-dev> betamax: If you're still looking for a way to login the script w/  username and password, it's pretty easy with the 'mechanize' library.  See my script for an example: https://github.com/vole-dev/Read-Alphabet-YahooGroups-Archive/blob/c3cd1b492a83d7e6b0722801c02a00af38e281bf/archive_group.py#L40

[16:57] <Lord_Nigh> actualy now that i check the dates, it looks those two trees are just  randomly committing stuff and not PRing it back to philpem 

[16:57] <Lord_Nigh> wild west of random code? not sure

[16:58] <Lord_Nigh> or just chaotic fast development due to impending yahoocalypse

[16:59] <Lord_Nigh> I've calmed down now.

[17:02] <balrog> Lord_Nigh: you should archive the public groups with cookies as well,  because that's the only way to get files/database/photos

[17:02] <@betamax> "chaotic fast development due to impending yahoocalypse"

[17:02] <@betamax> ^^ a very accurate representation

[17:03] <Lord_Nigh> i submitted the urls to the nominate tracker, i suppose I need to manually archive them too?

[17:03] <Lord_Nigh> the public ones

[17:03] <balrog> if they have files, photos, or attachments, yes

[17:03] <Lord_Nigh> the gbdev group is interesting since the moderators for that one went AWOL like 13 years ago

[17:03] == Jens [~jens@mimir.jensrex.dk] has joined #yahoosucks

[17:03] <@betamax> not necessarily

[17:04] <Lord_Nigh> and my membership was stuck in a pending state for over a decade

[17:04] <Lord_Nigh> but i checked today and apparently it somehow got approved

[17:04] <@betamax> for the URLs submitted to the google form, the goal will be to grab them completely if they allow non-admin approved joins

[17:04] <Lord_Nigh> or so it appears?

[17:05] <Lord_Nigh> those ones i submitted have the subtitle of "public group"

[17:05] <balrog> betamax: have you figured out a way to automate that joining?

[17:05] <@betamax> so any public groups submitted to the google form should get all files / etc... as well

[17:05] <Lord_Nigh> the ones i linked above have subtitle of "restricted group" where files are blocked but not messages, and the DX_Files group is the only one  set to "private group"

[17:06] <balrog> I believe it's like this:

[17:06] <balrog> "public group": anyone can view, anyone can join without mod approval

[17:06] <balrog> "restricted group": anyone can view, mod approval required to join

[17:06] <balrog> "private group": mod approval required to view anything

[17:06] <@betamax> balrog: kinda. tapedrive has developed a chrome extension which  automatically loads up a "high priority" group, you have to join it (and complete captcha) manually, the extension will detect that you've  joined, and give you another high priority group to join

[17:06] <balrog> for ALL the above, "anyone can view" refers ONLY to message history

[17:07] <balrog> files, photos, attachments, database, calendars ALL require joining, for ANY group, even if public

[17:07] <@betamax> soon (later today or tommorow) I'll be begging people on this channel to help out with that

[17:07] <@betamax> what balrog says is correct

[17:07] <@betamax> (there are a few weird cases where messages aren't visible even to members, but those are edge cases)

[17:10] <@betamax> balrog: there's also what I've been calling "pseudo-private" groups,  which are ones where you need to be a member to view, but you can join  without mod approval

[17:10] <@betamax> *need to be a member to view anything

[17:39] == VerifiedJ [~Joseph@host86-175-22-235.range86-175.btcentralplus.com] has joined #yahoosucks

[17:42] <Solanum> hello

[17:42] <Solanum> I was about a week into learning about this archiving stuff when this yahoo groups thing happened

[17:43] <Solanum> I am a trans man (aka FTM) and a lot of our history is on those groups

[17:43] <Solanum> they were very very important

[17:43] <Solanum> I am abit panicked trying to learn fast which doens't work

[17:45] <Solanum> All these groups are set to private

[17:45] <Solanum> Is there a page somewhere that you can reccomend me to read?

[17:45] <@betamax> Solanum: hi! thanks for stopping by

[17:46] <@betamax> by "private" do you mean that all new membership requests must be approved by an admin?

[17:46] <Solanum> Yes

[17:46] <Solanum> And some of them are inactive x years

[17:46] <Solanum> So it'll be a lot of work jsut to get into them

[17:46] <Solanum> But it's probably doable

[17:46] <@betamax> OK. Are you a member of all the groups you want to archive?

[17:46] <Solanum> Nope!

[17:47] <@betamax> right. That could be difficult.

[17:47] <Solanum> It's s mall community

[17:47] <Solanum> If I bother enough people I should be able to get in to at least some of them

[17:47] <@betamax> I would recommend trying to join them, then asking around to see if someone has already joined

[17:48] <@betamax> because it isn't strictly necessary for you to be a member, only that you can borrow the Yahoo account of someone who is

[17:48] <Solanum> Once I do that, is there a way to get the data? I was tryign to follow the chat above and it looks.. not straight forward

[17:48] <Solanum> hmm good point. they would need to trust me

[17:49] <@betamax> "chaotic fast development due to impending yahoocalypse" was one description of the work on the archival scripts right now

[17:49] <Solanum> OK maybe I'll give that a bit of time and work on getting access

[17:49] <Solanum> I have started a list https://calc.disroot.org/tijh1mt2c7v7

[17:50] <@betamax> basically, there are many tools to get just messages, and we're (or,  rather nico_32_ is) standardising on one tool to get everything from a  group

[17:50] <Solanum> I don't even know the names of all the groups. They are not a big thing now. But 10-20 years go.

[17:50] <@betamax> yes, access is the main thing

[17:50] <Solanum> Other than mesages what is there?

[17:50] <@betamax> photos / files / attachments / events / polls / links

[17:50] <Solanum> Right. Off course. 

[17:51] <Solanum> I will also need to convince people I am trustworthy. The groups are  private for ar eason, whcih is that people put very, very intimate  details fo their lives in them. 

[17:51] <Solanum> Like there are groups about genital surgery etc

[17:52] <@betamax> it is for that reason that "private" groups aren't going to be archived by us (archiveteam), although we will point you towards tools to do it  yourself

[17:52] <Solanum> Yes that's reasonable

[17:52] <@betamax> Yahoo are starting the first step towards closure on the 28th when they stop adding new content to the site

[17:52] <@betamax> there is a danger that at this point they no longer allow people to sign up to groups

[17:53] <@betamax> (the plan is for everything to eventually be invite-only)

[17:53] <Solanum> Yes I thoiught of that. i didn't know if it meant that or not. 

[17:53] <@betamax> so I would recommend getting access to all the groups you want to save by 28th Oct

[17:53] <@betamax> It's Yahoo... we're assuming the worst (although they did change it from the 21st to 28th, which is good)

[17:54] <Solanum> By the way if anyone else interested in LGBTQIAetcetc shows up, I can be reached at inthere@disroot.org 

[17:54] <Solanum> I am going to write something to send around to start on that. I wanted to know what there was by way of a plan for actually getting the data  before i started. Sounds like that is TBD at the moment

[17:55] <Solanum> Is this the best place to find updates or is there somewhere easier to catch up on?

[17:55] <@betamax> so, there is a script that can get everything (except maybe polls)

[17:55] <@betamax> but it is very flakey

[17:55] <Solanum> Can any member use it?

[17:55] <@betamax> yes, we'll have a solution at some point, hopefully mid-week at the latest

[17:56] <@betamax> https://github.com/nsapa/yahoo-group-archiver

[17:56] <@betamax> that's it there

[17:56] <Solanum> What about something like site-sucker or grab-site or wget?

[17:56] <@betamax> more difficult, as you'll need to deal with cookies and JS

[17:56] <Solanum> Those were the ones I was working on learning before I found out about this

[17:56] <Solanum> So they won't work really at all?

[17:57] <Solanum> Or will work but not ideally?

[17:57] <@betamax> they'll work for public groups, but not (without tweaking) for private groups

[17:57] <Solanum> because you need to be logged in?

[17:58] <@betamax> yes, and because some things on the site use javascript to load, which those other tools don't work as well on

[17:58] <Solanum> oh gosh

[17:59] <Solanum> I read something about using a cookies.txt file for logins for wget (or mabe grab-site) but if there is javascript for showing content.. that's a problem

[18:00] <@betamax> there may not be for messages, but I think things like images might not work as well

[18:01] <@betamax> hence the work on specialist tools just for Yahoo Groups

[18:01] <@betamax> we'll be releasing instructions on how to use the tools once they're ready

[18:01] <Solanum> I think getting anything would be better than nothing, but for the  groups I am hoping to get images are a huge component. People putt heir  surgery pics and other stuff like that. 

[18:02] <Solanum> I should watch the github linked above for thaT?

[18:03] <teovall> yes, momentum seems to be converging on that script... so that repo or  one of it's forks is likely to be the tool of choice going forward

[18:04] <Solanum> OK great

[18:04] <teovall> i'd say it's at the 80% point... 80-90% should go quick... it's that last 10% that will tough

[18:04] <Solanum> In the event that any of these groups are public, is there a list of  what has already been archived, or what is in the queue, so I don't have to spend time duplicating work?

[18:05] <@betamax> the best place to check is probably the wiki

[18:05] <Solanum> Ya there is usuallya. reason to leave certain bits til the end.. that they are extra difficult haha

[18:05] <@betamax> as we'll link to a tool and have instructions there once done

[18:06] <Solanum> this? https://www.archiveteam.org/index.php?title=Yahoo!_Groups

[18:06] <@betamax> tes

[18:06] <@betamax> *yes

[18:06] <Solanum> perfect thank you so much for taking your time

[18:06] <Solanum> <3

[18:06] <@betamax> if you find public groups, or ones that don't need member approval

[18:06] <@betamax> then we have a nomination form

[18:06] <@betamax> https://tinyurl.com/savegroups

[18:07] <@betamax> although if you want to be safe, archive it yourself as well

[18:07] <Solanum> OK noted

[18:11] == manjaro-u [~manjaro-u@kti.a12.18.ktis.net] has joined #yahoosucks

[18:11] == thuban1 has changed nick to thuban

[18:12] <nico_32_> Lord_Nigh: i have a pull request open

[18:12] <balrog> nico_32_: to which?

[18:12] <nico_32_> to my upstream philpem

[18:13] <balrog> ah I see

[18:13] <balrog> one thing we need is a configurable random-delay

[18:13] <balrog> between all requests to yahoo

[18:13] <balrog> in my experience in the past, that reduced/eliminated getting banned

[18:13] <balrog> I forget what specific parameters worked best but I think it was 1 or 2 seconds with randomness

[18:14] <Lord_Nigh> like wget --random-wait --wait=1.5 ?

[18:14] <balrog> yes, exactly

[18:15] <Jonas____> thanks @betamax that did the trick for HTTP 500 error (and thanks for  your script, it's litteraly saving synths history here)

[18:15] <teovall> this is how yahoo-groups-backup does it... https://github.com/rmcardle/yahoo-groups-backup/blob/master/yahoo_groups_backup/scraper.py#L176

[18:15] <balrog> with it set correctly I could capture large groups without getting IP banned

[18:15] <balrog> teovall: yeah I think I used yahoo_groups_backup most recently

[18:15] <@betamax> Jonas____: great, but it's probably best to re-run archival later this  week when we have a tool to do files / photos / etc..

[18:16] <thuban> <Solanum> In the event that any of these groups are public, is  there a list of what has already been archived, or what is in the queue, so I don't have to spend time duplicating work?

[18:16] <thuban> someone else also asked me this question

[18:16] <Jonas____> hi @Lord_Nigh I took care of yamahablackboxes but anyway a second copy  would be safer. ALso I'm not on DX_files so you can definitily save it !

[18:17] <thuban> there are the lists in the descriptions of the various scrapes on IA;  should I consolidate and add them to the wiki page (with a note that  they're message history only)? are there any other groups that have  already been scraped?

[18:17] == tech234a [uid352403@id-352403.stonehaven.irccloud.com] has quit [Quit: Connection closed for inactivity]

[18:17] <@betamax> those scrapes are PurpleSym's scrapes from a while ago

[18:18] == thuban [~weechat@c-73-211-96-74.hsd1.il.comcast.net]

[18:18] == realname : weechat

[18:18] == channels : #yahoosucks 

[18:18] == server  : efnet.portlane.se [Portlane EFnet Server (IPv4, IPv6 & SSL)]

[18:18] == End of WHOIS

[18:18] <@betamax> I think there should be an easier way to get a list of all of them, as  manually going through all those items could take a while

[18:18] <@betamax> also, all of those ones are public scrapes, so will almost certainly be re-done using the warrior

[18:18] <thuban> not necessarily... copy, xclip -o >>, sort | xclip -i

[18:19] <thuban> agreed, but as long as people are asking

[18:19] == girst [~girst@170.130.142.228] has quit [Quit: ZNC 1.7.5 - https://znc.in]

[18:19] == girst [~girst@170.130.142.228] has joined #yahoosucks

[18:19] <teovall> any list of stuff that's been archived should include what tool was  used and what version/commit of that tool so that if we find problems we can go back

[18:19] <@betamax> if people are asking about a specific group, get them to submit it to te google form

[18:19] <balrog> and what classes of data have been captured

[18:20] <balrog> also we should be careful not to run into a situation where someone has a large percentage of captures and loses them due to disk failure etc

[18:20] <Raccoon> hire amazon mechanical turks :)

[18:20] <@betamax> if it's a general "what are you archiving" then the answer is as many  public groups as we can find, and a small amount of high priority  pseudo-private groups

[18:20] <Raccoon> oops, scrolled up

[18:21] <@betamax> Raccoon: I assume you're talking about the captcha issue

[18:21] <Raccoon> caught me

[18:21] == manjaro-u [~manjaro-u@kti.a12.18.ktis.net] has quit [Quit: Konversation terminated!]

[18:21] <@betamax> we'll we will be essentially doing that, but with volunteers on this channel

[18:22] <@betamax> wanna sign up :)

[18:22] <thuban> betamax: i am willing to solve captchas

[18:22] <Raccoon> need to create a captcha crypto currency

[18:24] <Raccoon> might distract china for long enough they forget about hong kong

[18:24] == manjaro-u [~manjaro-u@kti.a12.18.ktis.net] has joined #yahoosucks

[18:24] <@betamax> thuban: that will be incredibly helpful

[18:24] <@betamax> tapedrive and I will be doing some (hopefully final) testing tonight / tomorrow, then we'll open it up

[18:26] <balrog> betamax: what are the plans for the archival scripts we'll go with?

[18:26] <Raccoon> i'd give it a whirl. maybe some scoring system or earn game credits in a turn based strategy

[18:27] <@betamax> if it's more than just a couple people I'll make a scoreboard

[18:27] <thuban> betamax: has poll support been added / is stuff merged?

[18:27] <@betamax> and a list at the end: group <x> was only saved because of the work of <y.

[18:27] <thuban> also, i thought of something wrt the raw / html messages issue

[18:27] <@betamax> nico_32_: ^^ question about poll support

[18:28] <@betamax> balrog: 99% sure we'll be using the script being worked on by nico_32_ for the more complex stuff

[18:29] <@betamax> although the warrior will likely just stick to downloading public messages only, and won't need a complex script

[18:29] <thuban> either a "yes, save both" flag or a "smart" setting can just check the  raw bytes for \ef\bf\bd and download message bodies only if there are  actually non-ascii characters

[18:30] <thuban> i think the affected case will be uncommon (over all groups, anyway)

[18:32] <thuban> unrelatedly, again: someone has asked whether there's an announcement page they could link to

[18:32] <thuban> i think the closest thing is the nominations form, but could someone  edit the introduction to add a link to the yahoo shutdown message?

[18:33] == steeph [webchat@p4FC75902.dip0.t-ipconnect.de] has joined #yahoosucks

[18:33] <steeph> Hi!

[18:33] <@betamax> thuban: an "announcements page"?

[18:33] <@betamax> if it's a Yahoo "announcement", then link to Yahoo help page

[18:34] <@betamax> otherwise probably link to the wiki

[18:34] <@betamax> steeph: hi!

[18:35] <steeph> I thought I could help saving YG content. I'm trying to install the python script.

[18:35] <@betamax> steeph: which one?

[18:35] <steeph> https://github.com/csaftoiu/yahoo-groups-backup

[18:35] <@betamax> work on the scripts is very much in progress, so things are changing all the time

[18:35] <steeph> "rainbowstream 1.3.7 has requirement requests==2.5.3, but you'll have requests 2.10.0 which is incompatible."

[18:35] <steeph> Should I ignore that?

[18:36] <@betamax> ehh, I'd actually recommend a different script

[18:36] <steeph> good

[18:36] <@betamax> nico_32_ is putting together one that can do everything (files / photos / polls / links ...)

[18:36] <steeph> Nice!

[18:37] <@betamax> it is at https://github.com/nsapa/yahoo-group-archiver/

[18:37] <steeph> That does sound better.

[18:37] <@betamax> although it is still work in progress

[18:37] <@betamax> and changes are being merged all the time

[18:37] <@betamax> if you want to help find bugs, issues, great!

[18:38] <@betamax> otherwise it may be best to wait a couple days until we have a more production-ready one

[18:40] <steeph> So using it now isn't productive until it's improved?

[18:41] <@betamax> probably not

[18:42] <@betamax> unless you want to help find bugs that may otherwise cause dataloss corruption when we start using the script intensively

[18:42] <steeph> Alright, thanks! I'll try it out.

[18:43] <thuban> betamax: the person who asked me about a page they could link others to also asked 'what is archiveteam', so it would be nice to have a psa  that's less technical and assumes less context than the wiki page

[18:43] <steeph> I'm not really a YG user. Any recommendations what to target for now?

[18:44] == thuban [~weechat@c-73-211-96-74.hsd1.il.comcast.net]

[18:44] == realname : weechat

[18:44] == channels : #yahoosucks 

[18:44] == server  : efnet.portlane.se [Portlane EFnet Server (IPv4, IPv6 & SSL)]

[18:44] == End of WHOIS

[18:44] <@betamax> steeph: yes

[18:44] <thuban> and i think the nominations form would be a good candidate (one click  to submit stuff, contact info right there) but the intro could use a  couple of links

[18:44] <Solanum> @thuban that is a very thoughtful idea

[18:44] <@betamax> steeph: find historically significant groups and nominate them with the form

[18:44] <thuban> shall i just request edit access?

[18:45] <@betamax> or just paste what you want here, and I'll change it

[18:45] <@betamax> steeph: https://tinyurl.com/savegroups <-- nominations form

[18:46] <thuban> betamax: i've sent a request, you don't want me drafting prose in an irc channel :)

[18:46] == scruss [webchat@206-248-137-140.dsl.teksavvy.com] has joined #yahoosucks

[18:48] <@betamax> thuban: I've added you now

[18:48] <@betamax> in case you wonder why that form is owned by someone called "Ban Krupcy",

[18:48] <@betamax> I have lots of disposable gmail accounts

[18:49] <@betamax> and a bad sense of humour

[18:49] <thuban> a good policy

[18:49] <Solanum> Since we're kind of on the topic

[18:49] <Solanum> does anyone know a way to SMS confirm a yahoo account without giving  out actual mobile phone number? The MySudo VOIP I usually use isn't  being accepted. 

[18:50] <@betamax> order lots and lots of free non-topped up pay-as-you-go sims?

[18:50] <@betamax> that's what I do

[18:50] <Raccoon> might be able to use a google voice phone number

[18:51] <Solanum> In canada i think it's a lot less cheap to do that than other places

[18:51] <@betamax> or use an existing email account, then it doesn't need a phone

[18:51] <thuban> "Adding hyperlinks on forms is currently not supported but you can add the web URL directlyto your forms." lol

[18:51] <Solanum> I did buy a second phone for this purpose but haven't go new SIM yet. I think it'll cost $40 or so

[18:52] <Solanum> But it mgiht actually be impossible to do anon

[18:52] <@betamax> huh, in the UK I can just request non-topped up pay-as-you-go SIMs, and they don't need credit to receive verification texts

[18:52] <Raccoon> how anon

[18:52] <Solanum> I had heard you could get anon at 7 11 but when I asked they said they'd need my ID etc

[18:52] <Solanum> For this purpose.. doesn't have to be TOO anon I guess. I just resent having to give anyone my ID

[18:53] <Solanum> trans people are a bit cagey about IDs.

[18:53] <Raccoon> i just mean create a Google Voice phone number attached to your mobile. Then verify Yahoo with it. Then delete it.

[18:53] <Solanum> like not all my ID matches exactly

[18:54] <Solanum> Oh I see. Maybe hat'll work let me try.

[18:54] <@betamax> I have used temporary email services in the past

[18:54] <Solanum> yahoo will take google voice you think?

[18:54] <@betamax> https://www.guerrillamail.com/inbox

[18:54] <Raccoon> most everything takes my google voice

[18:54] <@betamax> make a new email, then use that to sign uip to Yahoo, you will not need a phone number

[18:54] <@betamax> but make sure the email you use has ONLY letters and numbers in it

[18:55] <Raccoon> might depend on geoip. if you have a nigerian ip address, you have to submit dna

[18:55] <@betamax> because Yahoo groups doesn't like weird emails

[18:55] <Solanum> I have VPN I can be anywhere

[18:56] <Solanum> OH If you click "use your own email address" it doens't ask for a phone#

[18:56] <Solanum> doh

[18:59] <nico_32_> ok my branch now grab group descriptions & statistics

[18:59] <nico_32_> now doing the polls

[19:00] <steeph> I've created a new account with an @yahoo.com address. What's my  username to be used with the script? The part before the @ doesn't seem  to work.

[19:00] <nico_32_> steeph: use the cookie method, it work

[19:00] <steeph> k

[19:05] == tim_balle [webchat@c-73-56-102-102.hsd1.fl.comcast.net] has joined #yahoosucks

[19:07] == qwebirc40 [webchat@c-73-56-102-102.hsd1.fl.comcast.net] has joined #yahoosucks

[19:07] <steeph> SO, I'm fetching messages. What sort of things should I report?

[19:07] <steeph> "** Yahoo says this message has attachments, but I can't find any!"

[19:08] <thuban> done editing. acceptable PSA, guys?

[19:10] == tim_balle [webchat@c-73-56-102-102.hsd1.fl.comcast.net] has quit [Ping timeout: 260 seconds]

[19:11] <nico_32_> steeph: yes, sometime Yahoo doesn't have the file

[19:12] <nico_32_> when you go to the message with the browser, you don't see any attachment

[19:12] <nico_32_> poll api https://groups.yahoo.com/api/v1/groups/Polls/polls?status=DISABLED&orderBy=DATECREATED&sortOrder=DESC&start=21&count=10&chrome=raw&tz=America%2FLos_Angeles&ts=1571512212554

[19:12] == qwebirc40 [webchat@c-73-56-102-102.hsd1.fl.comcast.net] has quit [Quit: Page closed]

[19:12] <Solanum> Is there an email address you could add to the page as well as IRC and twitter?

[19:12] <Solanum> @thuban

[19:13] <thuban> main wiki page suggests archiveteam@archiveteam.org--does anyone actually man that?

[19:15] <steeph> https://pastecode.xyz/view/b3fbd9e3

[19:16] <Solanum> An email address would be a really good idea because most people aren't framiliar with IRN and many people are not on twitter

[19:17] <thuban> agreed... but only presuming someone will, in fact, read and answer that email; i don't know who if anyone has access to it

[19:17] <Solanum> Send an email and see if anyone answers. ;) 

[19:17] <thuban> lol, i guess that's one way

[19:18] <Solanum> My other question as an outsider reading it is: once this has been colelcted, where will it go?

[19:19] <thuban> mm, good point. i'll mention the internet archive (i assume that is the plan)

[19:22] <Solanum> If a group is private are you able to save it in some way that doens't involve posting for the whole internet?

[19:22] <Solanum> Or are you focussed on public only as a matter of priority?

[19:23] <thuban> public (or private-with-admin-consent) as a matter of practicality but also ethics

[19:23] <thuban> that said once there's a canonical script i'll be writing a tutorial on how to run it for groups you're a member of, and the plan is to point  members of groups with awol admins, etc, to that

[19:31] <Solanum> @thuban sorry what is the meanign of the word "canonical" in this context?

[19:31] <thuban> a finished version incorporating everyone's changes which supports everything we want to support

[19:32] <Solanum> thank you

[19:32] <thuban> almost everything is supported right now, but it's in a few different branches which need to be merged back together

[19:32] <satoshi> very old groups had their attachments wiped

[19:59] <Lord_Nigh> are any of the fork maintainers in here? i know philpem is, anyone else?

[19:59] <Lord_Nigh> stuff needs to be PR'ed, i think

[20:01] == Jonas____ [webchat@89.179.15.109.rev.sfr.net] has quit [Ping timeout: 260 seconds]

[20:11] == thuban [~weechat@c-73-211-96-74.hsd1.il.comcast.net] has quit [Read error: Connection reset by peer]

[20:12] == thuban1 [~weechat@c-73-211-96-74.hsd1.il.comcast.net] has joined #yahoosucks

[20:12] == thuban1 has changed nick to thuban

[20:15] == MaximeleG [~Thunderbi@lfbn-1-12084-254.w90-92.abo.wanadoo.fr] has joined #yahoosucks

[20:22] <nico_32_> Lord_Nigh: i am nsapa

[20:23] <nico_32_> and my fork is now grabbing Polls (@betamax)

[20:27] == sotty [webchat@ip4d1591ed.dynamic.kabel-deutschland.de] has joined #yahoosucks

[20:40] <@betamax> excellent!

[20:41] <@betamax> yes, canonical also in the sense that it has a standard output format

[20:41] <@betamax> and therefore (ideally) any tools that are developed later to process the data will work across all archives

[20:44] <teovall> i'm thinking we should save a log with date, time, script version  (maybe commit hash & modified files), relevant platform information, and an errors or abnormalities found during retreival and include that  with each groups archive

[20:52] == MaximeleG [~Thunderbi@lfbn-1-12084-254.w90-92.abo.wanadoo.fr] has quit [Quit: MaximeleG]

[20:55] == licensed [~licensed@45.173.102.168] has joined #yahoosucks

[21:04] <thuban> i'm trying to add html fetch for those encode errors, but i'm having trouble running the script at all--i get read timeouts

[21:04] <thuban> just scraping messages shouldn't require any auth at all, should it?

[21:07] <nico_32_> no, it can require auth

[21:08] <nico_32_> depend on the group permission

[21:11] <thuban> for public groups, i mean

[21:11] <thuban> anyway i just tried it with auth and had the same problem

[21:11] <@betamax> are you running it as python 2

[21:12] <thuban> concatenative works; cienciaficcion times out--can anyone replicate?

[21:12] <thuban> yes

[21:12] <thuban> (both work in browser)

[21:14] == licensed [~licensed@45.173.102.168] has quit [Quit: licensed]

[21:22] <Solanum> Do you folks think it's likely anyone else is working on this project,  or is the Archive Team the main group for this sort of thing?

[21:23] <Solanum> I'm trying to write about this and want to make sure not to miss something

[21:34] <thuban> Solanum: there are some private groups but i don't think anything as centralized. check @textfiles' twitter feed

[21:35] <thuban> also, it seems that it won't be possible to reliably do smart detection of encoding errors; some messages have them in both the raw and non-raw endpoints. (ex: https://groups.yahoo.com/api/v1/groups/turkmusikisi/messages/1000)

[21:36] == thuban [~weechat@c-73-211-96-74.hsd1.il.comcast.net]

[21:36] == realname : weechat

[21:36] == channels : #yahoosucks 

[21:36] == server  : irc.colosolutions.net [Colosolutions, Inc. - Orlando, FL]

[21:36] == End of WHOIS

[21:36] <thuban> probably this will vary based on the suckitude of the email/webmail client the poster was using.

[21:37] <thuban> (on the bright side, a lot of messages have special characters properly escaped with quoted-printable or w/e)

[21:38] <thuban> (and as such are unscathed in the raw endpoint)

[21:49] <balrog> nico_32_: I'm reluctant to run it without having a delay feature

[21:52] <Solanum> Are youse affiliated with whomeevr created this? https://docs.google.com/document/d/17fnAilYIKs08IxvgucJgPBJ3JUnSZNct_BGGKYnsidY/edit#

[21:55] <thuban> no, but it looks like we should coordinate with them

[21:56] <Solanum> source: https://www.reddit.com/r/DataHoarder/comments/dipcj6/all_of_yahoo_groups_is_being_rm_rfd_december_14/f4994je/

[21:58] <balrog> that's this person https://twitter.com/morgandawn6/status/1185254815065985024

[22:00] <thuban> betamax: i'm just going to remove the sketchy unescaping entirely. it'll be easier to handle it in post-processing

[22:01] <thuban> (html bodies can include html entities of non-ascii characters, which  aren't valid per email RFC, which the email module is bitchy about...)

[22:01] <balrog> oh the google doc has an email

[22:03] <Solanum> The form has a mandetory feild for "fandom" so I guess they ahve a narrow scope

[22:03] <Solanum> Maybe the Archive Team wiki could list special interest projects like theirs and mine? Would that be the most appropriate spot or somewhere else?

[22:07] <nico_32_> balrog: i run it for groups with 9k messages 

[22:07] <nico_32_> no issue

[22:07] <balrog> nico_32_: I have had issues with larger groups; I think others here have had issues as well?

[22:08] <balrog> they IP-ban for 24 hours

[22:09] <@betamax> some IPs don't get banned

[22:09] <@betamax> institutional IPs

[22:09] == MoffT [webchat@cha91-1-88-178-99-52.fbx.proxad.net] has joined #yahoosucks

[22:09] <balrog> betamax: huh interesting

[22:09] <balrog> I wonder which institutional IPs

[22:09] <@betamax> I've done 200,000 with no rate limiting and not yet been banned

[22:09] == mccz [webchat@45.12.220.227] has joined #yahoosucks

[22:09] <balrog> bc as I remember right IPs from my university (which has two /16s) would get banned

[22:10] <@betamax> I couldn't possible say :)

[22:10] <@betamax> *possibly

[22:10] == mccz [webchat@45.12.220.227] has quit [Client Quit]

[22:10] <nico_32_> # number of seconds to wait before trying again

[22:10] <nico_32_> HOLDOFF=10

[22:10] <balrog> that's for retries after an error, right?

[22:10] <balrog> not between any two requests

[22:10] <nico_32_> yes

[22:11] <nico_32_>               except requests.exceptions.HTTPError as err:

[22:11] <nico_32_>                 print "ERROR: can't download attachment, try %d: %s" % (i, err)

[22:11] <nico_32_>                 time.sleep(HOLDOFF)

[22:11] <balrog> hmm or does requests keep the http connection open and reuse?

[22:11] <nico_32_> also if there are a read error

[22:11] <nico_32_>       except requests.exceptions.ReadTimeout:

[22:11] <nico_32_>         print "ERROR: Read timeout, retrying"

[22:11] <nico_32_>         time.sleep(HOLDOFF)

[22:12] <teovall> delays should be easy to add... this is how the other script does it... https://github.com/rmcardle/yahoo-groups-backup/blob/master/yahoo_groups_backup/scraper.py#L176

[22:12] <nico_32_> pipelining ?

[22:12] <balrog> no, persistence or connection reuse

[22:12] <balrog> or keep-alive

[22:12] <balrog> it's possible yahoo doesn't block as quickly if you do that, not sure

[22:13] <nico_32_> connection reuse in http is pipelining 

[22:13] <nico_32_> and it is deprecated 

[22:14] <balrog> I didn't think so â€” I thought pipelining was sending more requests even if the response for the previous request was not received

[22:15] <nico_32_> no, pipelining is keeping the connection to the server open

[22:15] <nico_32_> and sending request after the last response have been received

[22:16] <balrog> https://brianbondy.com/blog/119/what-you-should-know-about-http-pipelining

[22:17] <balrog> apparently requests does automatic keep-alive: https://requests.kennethreitz.org//en/latest/user/advanced/#keep-alive

[22:22] <nico_32_> Connection: keep-alive

[22:22] <thuban> nico_32_: i've put in a pullreq for you

[22:22] <nico_32_> yeah ?

[22:22] <nico_32_> looking

[22:22] <thuban> (that retry pattern should be wrapped properly, but i think one of the other branches does it)

[22:23] <thuban> uh, don't merge yet, lemme fix a typo and push --force

[22:25] <thuban> done

[22:27] <nico_32_> unescape_html is used in archive_links & archive_photos & archive_files

[22:28] <nico_32_> the code use it in these function to create a "valid" unix filename

[22:28] <balrog> nico_32_: why would I get "login failed"?

[22:28] <balrog> are special chars in password not supported?

[22:29] <nico_32_> i don't the password authentification

[22:29] <nico_32_> only the cookie auth

[22:29] <thuban> nico_32_: oh, right

[22:29] <nico_32_> probably should remove the password auth

[22:29] <nico_32_> since it seem to work nowhere

[22:29] <thuban> is there some special reason that needs to be specifically those  characters, or can we use HTMLParser's unescape and call it a day?

[22:30] <nico_32_> no special reason i can see

[22:30] <nico_32_> just keep the swap of / to _

[22:30] <nico_32_> we keep the right name in the json anyway

[22:33] == MoffT [webchat@cha91-1-88-178-99-52.fbx.proxad.net] has quit [Quit: Page closed]

[22:33] <nico_32_> hum i wonder

[22:33] <thuban> albums, photos and links have the / _ replace, files don't

[22:33] <thuban> should they?

[22:33] <balrog> ah ok

[22:34] <balrog> nico_32_: I thought so - which means the readme is incorrect :)

[22:35] <nico_32_> thuban: they shouldn't

[22:35] <nico_32_> but keeping it isn't wrong

[22:35] <balrog> nico_32_: -ct and -cy?

[22:35] <nico_32_> yes

[22:36] <nico_32_> i have updated the README for cookie auth

[22:36] <nico_32_> :)

[22:36] <balrog> yeah, asking bc I got an auth error

[22:36] == sotty [webchat@ip4d1591ed.dynamic.kabel-deutschland.de] has quit [Quit: Page closed]

[22:36] <nico_32_> thuban: only forbidden characters in unix filename are / & \0

[22:36] <nico_32_> i don't believe we will get \0

[22:37] <balrog> oh I see why

[22:37] <thuban> nico_32_: is there no chance of getting / ?

[22:38] <nico_32_> the current UI reject /

[22:38] <thuban> ok

[22:39] <nico_32_> but add the swap anyway

[22:39] <teovall> shouldn't this be cross platform though? windows and macOS have more stringent filename requirements

[22:39] <nico_32_> maybe there is an old group with file created on MacOS classic

[22:40] <thuban> hm... i want to test these changes, but i'm getting 307'd on the files request

[22:40] <balrog> thuban: macOS allows / in GUI and allows : in CLI and maps one to the other

[22:40] <teovall> i mean, when the script is saving files... if a filename has a colon : for example, the file won't save on windows

[22:41] <thuban> i just joined the group, i can see stuff in browser, i reexported my  cookies, but script thinks it doesn't have read permission

[22:43] <nico_32_> look like the scripts is already broken

[22:43] <nico_32_> for foldername "AAA / AAA"

[22:43] <thuban> ?

[22:44] <balrog> ** Yahoo says this message has attachments, but I can't find any!

[22:44] <balrog> I get this a lot

[22:44] <nico_32_> thuban: you sure you have the right Y & T ?

[22:45] <nico_32_> T is very big

[22:45] <thuban> nico_32_: yep

[22:45] <balrog> and yeah the attachments are busted in web-ui too

[22:47] <thuban> i tried logging out and back in but no change

[22:48] <thuban> pushed the fix anyway... see if it works for you? i have to go for a while

[22:48] <nico_32_> ok looking

[22:55] == britm0b [~maxmo@pool-108-18-219-231.washdc.fios.verizon.net] has joined #yahoosucks

[22:56] == britm0b1 [~maxmo@pool-108-18-219-231.washdc.fios.verizon.net] has joined #yahoosucks

[22:56] == britm0b [~maxmo@pool-108-18-219-231.washdc.fios.verizon.net] has quit [Client Quit]

[22:56] == britm0b1 [~maxmo@pool-108-18-219-231.washdc.fios.verizon.net] has quit [Read error: Connection reset by peer]

[22:58] <nico_32_> UnicodeEncodeError: 'ascii' codec can't encode characters in position 13952-13954: ordinal not in range(128)

[22:59] <nico_32_> you know what

[23:02] <nico_32_> let's remove the whole eml things

[23:02] <nico_32_> there are dragon in encoding/decode 

[23:02] <nico_32_> just write the whole mess into raw file

[23:03] <thuban> eml is walked later

[23:03] <thuban> oh, i guess it's only for reattach... looks like that could be done in post-processing?

[23:04] <nico_32_> yes

[23:04] <nico_32_> going to remove the whole eml mess

[23:04] <nico_32_> will be easier

[23:12] <balrog> betamax, nico_32_: yeah, I'm around 24000 messages into a group and no bans yet, probably the keep-alive is preventing it

[23:13] <balrog> oh and it barfed on a 500

[23:13] == tech234a [uid352403@id-352403.stonehaven.irccloud.com] has joined #yahoosucks

[23:13] <balrog> the 500 happens in yahoo web-ui too

[23:16] <thuban> i just wrote morgan dawn and fanlore to see if we can coordinate, will report back

[23:16] <thuban> but i am really for real going now

[23:19] <@arkiver> odemgi: we'll get this one running, no worries :)

[23:20] <odemgi> eta?

[23:20] <@arkiver> I was thinking after everything goes read-only

[23:20] <balrog> nico_32_: thoughts about dealing with this 500?

[23:22] <nico_32_> 500 every time?

[23:22] <balrog> yep, on that specific message

[23:23] <balrog> and "Error loading" from webui

[23:23] <nico_32_> ignore it after 10 retry

[23:23] <nico_32_> and write an error log with its id

[23:23] <nico_32_> so we know what happened

[23:23] <teovall> are 500 deleted messages or something?

[23:24] <teovall> and good call on removing the eml code... simplifies things a lot

[23:26] <balrog> teovall: they might be

[23:26] <nico_32_> code in my repo is currently broke

[23:26] <nico_32_> fix in progress

[23:27] <@arkiver> nico_32_: what special status codes do we have

[23:27] <@arkiver> only 500?

[23:28] <balrog> lemme paste

[23:28] <balrog> https://gist.github.com/d235j/9b6f0b167c1485d5938e696a9caebcdb

[23:31] <teovall> hmm... i guess missing messages give 404 not 500

[23:33] == clkw [webchat@187.0.184.119] has joined #yahoosucks

[23:36] <@arkiver> odemgi: so that would be October 28, I'd say we start October 29

[23:36] <@arkiver> will get the scripts ready then

[23:37] <clkw> hello

[23:37] <@arkiver> hi

[23:37] <clkw> how can I help?

[23:37] <clkw> archive team warrior could be used for yahoo groups?

[23:37] <@arkiver> well wait and run a Warrior when the project is running

[23:37] <@arkiver> yes

[23:37] <@arkiver> project will be running October 29th

[23:38] <clkw> arkiver: nice, thanks

[23:38] <@arkiver> :)

[23:38] <odemgi> arkiver, sound 

[23:40] == clkw [webchat@187.0.184.119] has quit []

[23:43] <nico_32_> ok the code is now simpler for message

[23:43] <nico_32_> we don't mess with eml anymore

[23:43] <nico_32_> just written the raw json

[23:50] == scruss [webchat@206-248-137-140.dsl.teksavvy.com] has quit [Quit: Page closed]

[23:51] <nico_32_> balrog: is this group public ?

[23:52] <balrog> nico_32_: no, it's restricted

[23:53] <nico_32_> :(

[23:54] <nico_32_> could you give me your cookie in private?

[23:54] <nico_32_> (update the code, I removed the whole freaky eml things)

[23:55] <balrog> just did, it will still thrown an HTTP 500 though

[23:55] <balrog> throw*

[00:33] == sotty [webchat@ip4d1591ed.dynamic.kabel-deutschland.de] has joined #yahoosucks

[00:39] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has joined #yahoosucks

[00:40] <@dxrt> nico_32_: I keep getting crashes scraping internationalspacestation see https://pastebin.com/raw/33FHrVxV

[00:42] <nico_32_> hum

[00:42] <nico_32_> that mean that this message doesn't have an html message body

[00:47] <nico_32_> could you retry with the current version ?

[00:48] <@dxrt> yup, running now.

[00:50] == bvanevery [webchat@172.85.243.158] has joined #yahoosucks

[00:51] <bvanevery> I'm trying to figure out how to archive my mailing lists.

[00:51] <bvanevery> and to migrate one of them somewhere

[00:51] <nico_32_> hi

[00:52] <nico_32_> there are 3 python archiver that can grab every email

[00:52] <bvanevery> so I've read, but I've not seen much discussion of people actually using them?

[00:52] <bvanevery> maybe I need to go to the software lists themselves

[00:53] <nico_32_> mine works on the group I know

[00:53] <nico_32_> i am fixing the code for the rest

[00:53] <bvanevery> How do you verify that you actually got emails accurately?

[00:53] <balrog> usually I do spot checks on emails

[00:53] <bvanevery> seems like some kind of automated match compare would be valuable

[00:55] <bvanevery> well I'll try your stuff then in the next few days, see how it goes

[00:55] <bvanevery> gotta go now

[00:55] <balrog> feel free to come back if you need help

[00:57] <balrog> nico_32_: btw the raw endpoint still doesn't work right for unicode

[00:57] <balrog> https://groups.yahoo.com/api/v1/groups/cienciaficcion/messages/89704/raw

[00:58] <balrog> vs

[00:58] <balrog> https://es.groups.yahoo.com/neo/groups/cienciaficcion/conversations/messages/89704

[00:58] <balrog> I think betamax brought this up before

[00:58] <balrog> you get the unicode replacement character

[00:58] <balrog> (ef bf bd)

[00:59] == sotty [webchat@ip4d1591ed.dynamic.kabel-deutschland.de] has quit [Quit: Page closed]

[00:59] <balrog> also vs

[00:59] <balrog> https://groups.yahoo.com/api/v1/groups/cienciaficcion/messages/89704

[00:59] == bvanevery [webchat@172.85.243.158] has quit [Ping timeout: 260 seconds]

[00:59] <balrog> this means we have to capture both /raw and non-/raw

[01:00] <balrog> for each message

[01:02] <nico_32_> we are capturing raw and not raw

[01:02] <nico_32_> we write the raw json and html body

[01:02] <balrog> there's non-raw json too apparently

[01:02] <balrog> if you leave /raw off the API URK

[01:02] <balrog> URL*

[01:03] <balrog> and that has proper unicode

[01:03] <balrog> or you mean we're writing the body of that?

[01:03] <balrog> imo we should keep both JSON files for each message

[01:04] <nico_32_> we are doing this currently

[01:04] <nico_32_>     with file("%s_raw.json" % (id,), 'wb') as f:

[01:04] <nico_32_>       f.write(json.dumps(raw_json, indent=4))

[01:04] <nico_32_> 		  with file("%s.html" % (id,), 'w') as f:

[01:04] <nico_32_> 		    f.write(html_json['messageBody'].encode('utf-8'))

[01:04] <balrog> I see what you mean... yeah

[01:04] <nico_32_> raw_json come from the raw endpoint

[01:04] <balrog> and html_json comes from the non-raw endpoint

[01:04] <balrog> though we're not writing the full json, just the html file

[01:04] <balrog> or data rather

[01:04] <nico_32_> html_json come from the non-raw

[01:05] <nico_32_> there are not much in the non-raw endpoint

[01:06] <nico_32_> but okay I can write the whole object

[01:06] <teovall> the non-raw endpoint has the attachment info though

[01:07] <balrog> imo we should preserve more rather than less â€” maybe not full  WARC-level stuff (WARC dumps HTTP headers and such), but definitely API  responses in full

[01:09] <Solanum> I have made a quick webpage for my specific project, if anyone wants to look at it and let me know of any feedback: https://archivetransyahoo.noblogs.org

[01:09] <nico_32_> true

[01:11] == testi [webchat@p4FF8225C.dip0.t-ipconnect.de] has quit [Quit: Page closed]

[01:13] <teovall> good stuff Solanum... found a typo here though... "For archives which  are created but held privately, figure out a way that information about  the whereabouts of these can be share with anyone in the future who  might require them"... share should be shared

[01:15] <Solanum> thank you fixed

[01:17] <teovall> thanks for taking that on and getting some notice about it... i think  its an important thing to save... both for the trans community and for  historical sake

[01:18] <Solanum> I hope I am able to a) track down those with access, and b) convince them to let me into the groups.

[01:19] <teovall> i hope so too

[01:20] <nico_32_> going to sleep

[01:20] <teovall> goodnight

[01:20] <Solanum> gn zzzzz

[01:20] <nico_32_> let's hope my master branch isn't broken :)

[01:20] <Raccoon> is the Ya!hoover sucking yet?

[01:23] == tech234a [uid352403@id-352403.stonehaven.irccloud.com] has quit [Quit: Connection closed for inactivity]

[01:23] == DogsRNice [~DogsRNice@2600:1700:7480:95f0:646f:ba30:bd1:dc1a] has quit [Read error: Connection reset by peer]

[01:26] <Solanum> I am a bit puzzled because search results page list different dates than individual group pages

[01:26] <Solanum> for example one group says "klast activity" sometime in 2016 but the group page lists 1 or 2 posts/month until september 19

[01:27] <Solanum> Sometimes the information is the same on both

[01:29] <balrog> Solanum: it's *critical* you keep track of multiple contact people per group with this kind of stuff

[01:30] <Solanum> sorry?

[01:30] == mode/#yahoosucks [+oo balrog nico_32_] by dxrt

[01:33] <@dxrt> nico_32_: Oh man, new code fixed it, however when trying a file: https://pastebin.com/raw/dKpeRVjK. Am not signed in.

[01:36] <@dxrt> Got all the posts but I guess cleaner error handling on files.

[01:36] <@nico_32_> yeah 

[01:36] <@nico_32_> WIP

[01:36] <@dxrt> cool. will keep on testing.

[01:37] <@balrog> Solanum: meaning â€” so you don't end up with a situation where you have  data archived but can't get permission/clearance to send it to anyone.  Also â€” group operators need to archive their user lists

[01:37] == X-Scale` [~ARM@83.223.243.222] has joined #yahoosucks

[01:37] == X-Scale [~ARM@31.22.160.25] has quit [Ping timeout: 240 seconds]

[01:37] == X-Scale` has changed nick to X-Scale

[01:38] <@nico_32_> dxrt: you can select what you want to save

[01:38] <@nico_32_> if files is disabled

[01:38] <@nico_32_> links or database could works

[01:39] <@nico_32_> so ./yahoo.py -l -p -i -d -c -a

[01:41] <@dxrt> ok

[01:53] <Solanum> @balrog I didn't understand what you were trying to say up there

[01:58] <Solanum> Oh sorry nevermind I see the 2nd message

[02:10] == manjaro-u [~manjaro-u@kti.a12.18.ktis.net] has quit [Read error: Operation timed out]

[02:17] == X-Scale [~ARM@83.223.243.222] has quit [Ping timeout: 240 seconds]

[02:22] == X-Scale [~ARM@83.223.235.119] has joined #yahoosucks

[02:34] == arrow22 [~arrow22@104.128.136.46] has joined #yahoosucks

[02:52] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has quit [Ping timeout: 260 seconds]

[03:18] <superkuh> For the nominations list, do you want the url like, https://groups.yahoo.com/neo/groups/Coronado_PST/info ?

[03:24] <thuban> superkuh: yes, that's fine

[03:27] <superkuh> Thanks.

[03:28] == steeph [webchat@p4FC75902.dip0.t-ipconnect.de] has quit [Ping timeout: 260 seconds]

[03:46] == patsen29 [webchat@CPE9050ca208cf3-CM9050ca208cf0.cpe.net.cable.rogers.com] has quit [Ping timeout: 260 seconds]

[03:52] == odemgi_ [~odemgi@200116b8248e78003efdff9a16543c2b.dip.versatel-1u1.de] has joined #yahoosucks

[03:54] == odemgi [~odemgi@2001:16b8:2c07:eb00:1926:999c:7d4d:1820] has quit [Ping timeout: 252 seconds]

[04:00] == teovall [~teovall@li558-181.members.linode.com] has quit [Quit: Ping timeout (120 seconds)]

[04:00] == qw3rty2 [~qw3rty@92.116.144.233] has joined #yahoosucks

[04:00] == teovall [~teovall@li558-181.members.linode.com] has joined #yahoosucks

[04:06] == Igloo_ [~Igloo@ks383241.kimsufi.com] has joined #yahoosucks

[04:06] == Igloo [~Igloo@ks383241.kimsufi.com] has quit [Read error: Connection reset by peer]

[04:08] == qw3rty [~qw3rty@92.116.130.10] has quit [Ping timeout: 745 seconds]

[04:12] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has joined #yahoosucks

[04:18] == LordNigh2 [Lord_Nigh@pool-108-52-174-156.phlapa.fios.verizon.net] has joined #yahoosucks

[04:18] == Raccoon [~waywerd@194.34.133.208] has quit [se.hub efnet.portlane.se]

[04:18] == Deewiant [~deewiant@de1.ut.deewiant.iki.fi] has quit [se.hub efnet.portlane.se]

[04:18] == Lord_Nigh [Lord_Nigh@pool-108-52-174-156.phlapa.fios.verizon.net] has quit [se.hub efnet.portlane.se]

[04:19] == Raccoon [~waywerd@194.34.133.208] has joined #yahoosucks

[04:19] == Deewiant [~deewiant@de1.ut.deewiant.iki.fi] has joined #yahoosucks

[04:24] == Decobus [~quassel@c-76-112-88-95.hsd1.mi.comcast.net] has joined #yahoosucks

[04:25] <Decobus> Just a question...when is the Archive Warrior going to start giving out Yahoo group assignments? I assume after the nomination period??

[04:27] <thuban> Decobus: the archive script is not yet finalized (work needs to be  merged and tested); the warrior won't be ready until it is. the goal is  on or before the 29th

[04:33] == superkuh [~superkuh@c-24-118-172-137.hsd1.wi.comcast.net] has quit [Excess Flood]

[04:33] == teovall [~teovall@li558-181.members.linode.com] has quit [Read error: Connection reset by peer]

[04:34] == LordNigh2 has changed nick to Lord_Nigh

[04:37] == fallenoak [sid239139@id-239139.highgate.irccloud.com] has joined #yahoosucks

[04:44] == superkuh [~superkuh@c-24-118-172-137.hsd1.wi.comcast.net] has joined #yahoosucks

[04:45] == teovall [~teovall@li558-181.members.linode.com] has joined #yahoosucks

[04:49] == vole-dev [~akovaski@99-12-190-228.lightspeed.milwwi.sbcglobal.net] has quit [Read error: Operation timed out]

[04:54] == Igloo_ [~Igloo@ks383241.kimsufi.com] has quit [Read error: Connection reset by peer]

[04:54] == Datechnom [~Panda@180-150-73-100.b49649.syd.nbn.aussiebb.net] has quit [Read error: Connection reset by peer]

[04:57] == satoshi [~serv@201.131.87.128.wireless.tknet-ti.com.br] has quit [Ping timeout: 360 seconds]

[04:58] == superkuh [~superkuh@c-24-118-172-137.hsd1.wi.comcast.net] has quit [Excess Flood]

[05:02] <thuban> betamax: in re asking admins of private groups for consent--is there/will there be a dedicated archiveteam account?

[05:02] == tech234a [uid352403@id-352403.stonehaven.irccloud.com] has joined #yahoosucks

[05:02] <thuban> for membership, i mean

[05:02] == superkuh [~superkuh@c-24-118-172-137.hsd1.wi.comcast.net] has joined #yahoosucks

[05:04] <thuban> seems like a good idea for preventing (a) exposing data between  volunteers and (b) splintering access (would hate to have to contact  admins multiple times because original person went awol)

[05:06] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has quit [Ping timeout: 260 seconds]

[05:22] == MrRadar [~pi@75-168-88-2.mpls.qwest.net] has quit [Read error: Connection reset by peer]

[05:23] <Raccoon> Are there considerations for just filtering out entire groups based on type? For instance, Yahoo Groups were largely the original CraigsList, and then  there are some tens of thousands of City Freecycle groups and City  Yardsale groups

[05:23] <Raccoon> not sure if it's critical to archive people cleaning out their closets

[05:23] <Raccoon> complete with street addresses and phone numbers

[05:24] <Solanum> Has it been possible to generate a list of allt he groups?

[05:24] <Raccoon> I've made provisions to privatize / close all the groups I adminned for my local town

[05:25] <Solanum> Last Freecycle group I was on totally shit show... so mcuh drama you  woudn't believe,. There were slipts and multiple groups in the city. 

[05:25] <Raccoon> (100% closet clean-out groups)

[05:25] <Solanum> *splits

[05:26] <Raccoon> Yeah, it took some really strong and wise admins to write policy and moderate effectively

[05:26] <Solanum> I don't know if weirdy cliques are of interest to future historians,  but closet cleaning was def not the primary activity being carried out

[05:26] <Raccoon> No Mary Kay, no pets, etc.

[05:27] <Solanum> Is therhe a list of all the groups?

[05:27] <Raccoon> i don't know what Yahoo's searchability is all about

[05:28] <Solanum> If there is a list of the groups would it be poeeible (in a way that  wasn't spam and didn't get anyone in trouble) to send a notice to allt  he mods notifying them of the possibility to archive?\

[05:28] <Raccoon> I think that's what's going on

[05:28] <Solanum> Oh ok. Cause word of mouth won't reach most people. WOUld ahve to be a bit cold cally

[05:29] <Raccoon> [19:29] <@balrog> Solanum: it's *critical* you keep track of  multiple contact people per group with this kind of stuff

[05:29] <Raccoon> [19:36] <@balrog> Solanum: meaning â€” so you don't end up with a  situation where you have data archived but can't get  permission/clearance to send it to anyone. Also â€” group operators need  to archive their user lists

[05:29] <Solanum> huh?

[05:30] <Solanum> were those supposed to be connected with the immediately previous convo? if so i have missed it

[05:30] <thuban> Solanum: mind if i link to your spreadsheet of trans groups on the wiki page?

[05:30] <Raccoon> just a copy/paste from earlier that seems like the intention is to contact all admins

[05:30] <Solanum> Like as a demo?

[05:30] <Solanum> I gave up on working in ethpad

[05:30] <Raccoon> I don't have an @ before my name, so I don't have these answers

[05:31] <Solanum> My actual working document is in open office, which sucks marginally less

[05:32] <Solanum> What do you mean you don't ahve an @? Cna't anyone even @Racoon have an @?

[05:32] <Raccoon> @ == channel operator == project manager [generally]

[05:32] <Solanum> Oh does it mean they are an admin?

[05:32] <Solanum> right

[05:32] <Solanum> But why did you copy and paste those lines from way back just now?

[05:33] <thuban> Solanum: ah, ok. please consider dumping public groups to the nomination form and private groups to the wiki section!

[05:33] <Solanum> I haven't found any public groups

[05:34] <Raccoon> Solanum, I thought they were contextual. if I'm wrong, my apologies

[05:34] <Solanum> I don't think I will

[05:34] <Solanum> *I don't think i will find any open groups

[05:34] == arrow22 [~arrow22@104.128.136.46] has quit [Leaving]

[05:35] <Solanum> But what I am doing works in a spreadsheet cause there are a couple of dozen.. for all of yahoo presumably you'd need a bot

[05:39] <thuban> whew, just sent a LONG-ass email to the OTW people organizing their thing

[05:41] <Solanum> what about if i can ask?

[05:44] <teovall> OTW?

[05:44] <Solanum> ya

[05:45] <Solanum> i am just curious about how this is all working if you don't want or are too tired to explain it all that's fine

[05:46] <thuban> otw is the organization for transformative works--basically, fanfic and fan culture, including documentation thereof; they are pretty big in  that space

[05:47] <Solanum> Oh ya I know them they have a huge collection of very strange smut

[05:47] <Solanum> I get the impression thatthey have $$$ because there always seem to be job posting

[05:48] <Solanum> (or mayb a terrible place to work.. the other things that would explain frequent posting)

[05:49] <thuban> (from what i have heard of it, a little from column a, a little from column b)

[05:50] <thuban> (they do REALLY well for a mostly-volunteer non-profit, but that kind of beast is what it is)

[05:51] <thuban> anyway i just found out they had a psa out about yahoo groups (a LOT of fanfic used to be published there), but it didn't mention us and its  suggestions wrt archival were more 'here's how you can' / 'here's what  somebody did' than 'we're getting everything and putting it somewhere  accessible'

[05:52] <thuban> so i suggested pointing people to us

[05:52] <Solanum> They probably didn't know about you

[05:52] <thuban> i expect so

[05:53] <Solanum> Maybe you guys can make a page to link to specific projects for certain areas, like they and i are doing

[05:53] <Solanum> In case someone wants to archive all the freecycles

[05:54] <thuban> we can make subpages under the wiki page for that, if the private-groups-of-interest section gets too big

[05:54] <thuban> but that would be getting ahead of ourselves since it still has two entries

[05:56] <Solanum> If you add this you can have 3 entires: The Project to Archive Trans Yahoo Groups

[05:56] <Solanum> https://archivetransyahoo.noblogs.org

[06:02] == phirephly [~kenneth@44.4.17.2] has quit [Ping timeout: 360 seconds]

[06:05] <Solanum> ok enough columns and rows tonight. nice chatting. zzzzz

------

[06:06] <thuban> night

[06:08] == phirephly [~kenneth@44.4.17.2] has joined #yahoosucks

[06:08] == markedL [~markedL@c-73-115-59-250.hsd1.tx.comcast.net] has quit [Quit: The Lounge - https://thelounge.chat]

[06:11] == markedL [~markedL@c-73-115-59-250.hsd1.tx.comcast.net] has joined #yahoosucks

[06:12] == mode/#yahoosucks [+o markedL] by svchfoo3

[06:13] == Datechnom [~Datechnom@180-150-73-100.b49649.syd.nbn.aussiebb.net] has joined #yahoosucks

[06:14] == MrRadar [~pi@75-168-88-2.mpls.qwest.net] has joined #yahoosucks

[06:20] == markedL [~markedL@c-73-115-59-250.hsd1.tx.comcast.net] has quit [Quit: The Lounge - https://thelounge.chat]

[06:21] == markedL [~markedL@c-73-115-59-250.hsd1.tx.comcast.net] has joined #yahoosucks

[06:21] == mode/#yahoosucks [+o markedL] by svchfoo3

[06:21] == DFJustin [DopefishJu@S0106802aa89d5ec8.pk.shawcable.net] has joined #yahoosucks

[06:34] == Igloo [~Igloo@ks383241.kimsufi.com] has joined #yahoosucks

[06:36] == Lord_Nigh [Lord_Nigh@pool-108-52-174-156.phlapa.fios.verizon.net] has quit [Ping timeout: 252 seconds]

[06:38] <Raccoon> found the solution to captchas. https://lolsnaps.com/wp-content/uploads/2019/06/n51t0o4thz531.jpg

[06:40] == Lord_Nigh [Lord_Nigh@pool-108-52-174-156.phlapa.fios.verizon.net] has joined #yahoosucks

[07:10] == wp494 [~wp494win7@S0106bcd16568841b.wp.shawcable.net] has quit [Ping timeout: 252 seconds]

[07:12] == tech234a [uid352403@id-352403.stonehaven.irccloud.com] has quit [Quit: Connection closed for inactivity]

[07:23] == Raccoon [~waywerd@194.34.133.208] has quit [se.hub efnet.portlane.se]

[07:23] == Deewiant [~deewiant@de1.ut.deewiant.iki.fi] has quit [se.hub efnet.portlane.se]

[07:23] == Raccoon` [~waywerd@194.34.133.208] has joined #yahoosucks

[07:39] == Deewiant [~deewiant@de1.ut.deewiant.iki.fi] has joined #yahoosucks

[07:43] == thuban1 [~weechat@c-73-211-96-74.hsd1.il.comcast.net] has joined #yahoosucks

[07:49] == thuban [~weechat@c-73-211-96-74.hsd1.il.comcast.net] has quit [Read error: Operation timed out]

[07:51] == Deewiant [~deewiant@de1.ut.deewiant.iki.fi] has quit [Ping timeout: 258 seconds]

[07:57] == wp494 [~wp494win7@S0106bcd16568841b.wp.shawcable.net] has joined #yahoosucks

[08:49] == kiskabak [james@104.168.61.80] has quit [Read error: Operation timed out]

[08:50] == seednode [~seednode@stop.blaming.me] has quit [Read error: Operation timed out]

[08:52] == sep332 [~sep332@mc1.metrocast.net] has quit [Read error: Operation timed out]

[08:52] == benjins [~Benjins@pool-71-174-239-234.bstnma.fios.verizon.net] has quit [Read error: Operation timed out]

[08:54] == phillipsj [~phillipsj@107-190-70-146.cpe.teksavvy.com] has quit [Read error: Operation timed out]

[08:55] == Fusl [fusl@1.0.0.127.in-addr.arpa.li] has quit [Read error: Operation timed out]

[08:55] == PurpleSym [~ppsym@luna.6xq.net] has quit [Read error: Operation timed out]

[08:55] == PurpleSym [~ppsym@luna.6xq.net] has joined #yahoosucks

[08:56] == mode/#yahoosucks [+o PurpleSym] by svchfoo3

[08:56] == benjins [~Benjins@pool-71-174-239-234.bstnma.fios.verizon.net] has joined #yahoosucks

[08:56] == Fusl [~fusl@1.0.0.127.in-addr.arpa.li] has joined #yahoosucks

[09:00] == phillipsj [~phillipsj@107-190-70-146.cpe.teksavvy.com] has joined #yahoosucks

[09:01] == arkiver [~arkiver@199.241.31.225] has quit [Read error: Operation timed out]

[09:02] == seednode [~seednode@stop.blaming.me] has joined #yahoosucks

[09:04] == arkiver [~arkiver@199.241.31.225] has joined #yahoosucks

[09:04] == mode/#yahoosucks [+o arkiver] by svchfoo3

[09:04] == mode/#yahoosucks [+o arkiver] by svchfoo1

[09:41] == dxrt_ [~dxrt_@192.73.238.114] has quit [Read error: Operation timed out]

[09:41] == JAA [~JAA@131.ip-144-217-81.net] has quit [Read error: Operation timed out]

[09:41] == balrog [~balrog@pool-108-52-208-125.phlapa.fios.verizon.net] has quit [Read error: Operation timed out]

[09:41] == Stilettoo [~Stiletto@24.102.227.87] has joined #yahoosucks

[09:41] == kiska18 [james@172.82.152.29] has quit [Read error: Operation timed out]

[09:42] == kiska2 [james@216.21.8.63] has quit [Read error: Operation timed out]

[09:42] == balrog [~balrog@pool-108-52-208-125.phlapa.fios.verizon.net] has joined #yahoosucks

[09:42] == svchfoo1 [~chfoo1@nullhound.fart.website] has quit [Read error: Operation timed out]

[09:42] == jodizzle [~jodizzle@46.101.163.45] has quit [Read error: Operation timed out]

[09:42] == mode/#yahoosucks [+o balrog] by svchfoo3

[09:43] == Stiletto [~Stiletto@24.102.227.87] has quit [Ping timeout: 246 seconds]

[09:43] == atrocity [~atrocity@47.200.78.7] has quit [Read error: Operation timed out]

[09:44] == atrocity [~atrocity@47.200.78.7] has joined #yahoosucks

[09:45] == wp494 [~wp494win7@S0106bcd16568841b.wp.shawcable.net] has quit [west.us.hub irc.Prison.NET]

[09:45] == phirephly [~kenneth@44.4.17.2] has quit [west.us.hub irc.Prison.NET]

[09:45] == superkuh [~superkuh@c-24-118-172-137.hsd1.wi.comcast.net] has quit [west.us.hub irc.Prison.NET]

[09:46] == phirephl- [~kenneth@44.4.17.2] has joined #yahoosucks

[09:47] == superkuh_ [~superkuh@c-24-118-172-137.hsd1.wi.comcast.net] has joined #yahoosucks

[09:57] == jodizzle [~jodizzle@46.101.163.45] has joined #yahoosucks

[09:58] == mode/#yahoosucks [+o jodizzle] by svchfoo3

[10:08] == X-Scale` [~ARM@83.223.235.119] has joined #yahoosucks

[10:09] == X-Scale [~ARM@83.223.235.119] has quit [Ping timeout: 240 seconds]

[10:09] == X-Scale` has changed nick to X-Scale

[10:10] == wp494 [~wp494win7@S0106bcd16568841b.wp.shawcable.net] has joined #yahoosucks

[10:41] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has joined #yahoosucks

[10:42] == kiska2 [james@216.21.8.63] has joined #yahoosucks

[10:42] == mode/#yahoosucks [+o kiska2] by svchfoo3

[10:42] == dxrt_ [~dxrt_@192.73.238.114] has joined #yahoosucks

[10:42] == kiska18 [james@172.82.152.29] has joined #yahoosucks

[10:43] == svchfoo1 [~chfoo1@nullhound.fart.website] has joined #yahoosucks

[10:43] == mode/#yahoosucks [+o dxrt_] by dxrt

[10:43] == mode/#yahoosucks [+o kiska18] by svchfoo3

[10:44] == mode/#yahoosucks [+o svchfoo1] by svchfoo3

[10:46] == JAA [~JAA@131.ip-144-217-81.net] has joined #yahoosucks

[10:46] == mode/#yahoosucks [+o JAA] by AlsoJAA3

[11:07] == odemgi_ [~odemgi@200116b8248e78003efdff9a16543c2b.dip.versatel-1u1.de] has quit [Read error: Connection reset by peer]

[11:08] == odemgi_ [~odemgi@200116b8248e78003efdff9a16543c2b.dip.versatel-1u1.de] has joined #yahoosucks

[11:12] == odemgi_ [~odemgi@200116b8248e78003efdff9a16543c2b.dip.versatel-1u1.de] has quit [Read error: Connection reset by peer]

[11:12] == odemgi_ [~odemgi@200116b8248e78003efdff9a16543c2b.dip.versatel-1u1.de] has joined #yahoosucks

[12:13] == Jonas__ [webchat@89.179.15.109.rev.sfr.net] has joined #yahoosucks

[12:13] <Jonas__> hi everybody

[12:16] <odemgi_> ello poppet 

[13:10] <@markedL> um, anyone else wondering where the robot got that hand from? 

[13:16] <odemgi_> shelf by the door

[13:18] == Jonas__ [webchat@89.179.15.109.rev.sfr.net] has quit [Ping timeout: 260 seconds]

[13:30] == astrid [~chronomex@xn--ng-pma6851a.xrtc.net] has quit [Ping timeout: 1212 seconds]

[13:55] == queenmab [webchat@ip70-161-250-153.hr.hr.cox.net] has joined #yahoosucks

[14:08] == Hani111 [~Hani@212-149-181-30.bb.dnainternet.fi] has joined #yahoosucks

[14:20] == Hani [~Hani@ddn5lkyrgnw6f-46g3wtt-3.rev.dnainternet.fi] has quit [Ping timeout: 745 seconds]

[14:20] == Hani111 has changed nick to Hani

[14:36] == macdude22 [~macdude22@2604:2d80:588a:1900:152f:7ccd:4bf3:75f9] has joined #yahoosucks

[14:47] == MaximeleG [~Thunderbi@lfbn-1-12084-254.w90-92.abo.wanadoo.fr] has joined #yahoosucks

[14:49] == vole-dev [~akovaski@99-12-190-228.lightspeed.milwwi.sbcglobal.net] has joined #yahoosucks

[14:53] <@balrog> nico_32_: the group 'mailstation' is giving me trouble with downloading files â€” SSL errors

[15:07] <@balrog> nico_32_: additionally the public group 'macdrivers' doesn't seem to be downloading all attachments

[15:07] <@balrog> (see e.g. message 2426)

[15:09] <@balrog> nico_32_: also why aren't we using the /groups/GROUPNAME/attachments/ api endpoint to scrape the attachments separately?

[15:10] <@balrog> looks like that endpoint gives us the list of attachments for the  group, and attachment IDs, which we can then use to get the json for  each attachment, which contains the attachment details and the download  URL

[15:11] <@balrog> that way we won't miss attachments (e.g. with the 'macdrivers' group)

[15:11] <@balrog> anyway I have to go, bbl

[15:17] == asdf [webchat@c-24-21-236-69.hsd1.or.comcast.net] has quit [Ping timeout: 260 seconds]

[15:42] == oohoo [webchat@c-73-71-10-181.hsd1.ca.comcast.net] has joined #yahoosucks

[15:44] == oohoo [webchat@c-73-71-10-181.hsd1.ca.comcast.net] has quit [Client Quit]

[16:04] == macdude22 [~macdude22@2604:2d80:588a:1900:152f:7ccd:4bf3:75f9] has quit [Quit: Textual IRC Client: [www.textualapp.com](http://www.textualapp.com)]

[16:06] == n_ [webchat@cpe-74-78-60-250.maine.res.rr.com] has joined #yahoosucks

[16:07] == n_ [webchat@cpe-74-78-60-250.maine.res.rr.com] has quit [Client Quit]

[16:11] <queenmab> Does yahoosucks have logs?

[16:15] == Stiletto [~Stiletto@24.102.227.87] has joined #yahoosucks

[16:18] == Stilettoo [~Stiletto@24.102.227.87] has quit [Read error: Operation timed out]

[16:18] <Igloo> Yes queenmab 

[16:18] <Igloo> WHat's up?

[16:20] == satoshi [~serv@201.131.87.128.wireless.tknet-ti.com.br] has joined #yahoosucks

[16:24] <queenmab> I want to read up on anything I missed but I don't know how.

[16:26] == macdude22 [~macdude22@173-24-19-15.client.mchsi.com] has joined #yahoosucks

[16:31] == balrog [~balrog@pool-108-52-208-125.phlapa.fios.verizon.net] has quit [Quit: Bye]

[16:31] <Igloo> Oh, Seems the logger isn't here.

[16:31] <Igloo> Others have logs

[16:38] <@markedL> who's repo is closest to canonical now? we can put it in the topic

[16:42] == balrog [~balrog@pool-108-52-208-125.phlapa.fios.verizon.net] has joined #yahoosucks

[16:42] == mode/#yahoosucks [+o balrog] by svchfoo1

[16:42] == mode/#yahoosucks [+o balrog] by svchfoo3

[16:42] == markedL changed the topic of #yahoosucks to: Closing Oct 28/Dec 14: help.yahoo.com/kb/groups/SLN31010.html |  archiveteam.org/index.php?title=Yahoo!_Groups | Nominate:  tinyurl.com/savegroups

[16:50] == markedL changed the topic of #yahoosucks to: Closing Oct 28/Dec 14: help.yahoo.com/kb/groups/SLN31010.html |  archiveteam.org/?title=Yahoo!_Groups | Nominate: tinyurl.com/savegroups

[16:51] <Igloo> I hope that the archiveteam one is...

[17:05] <@markedL> well no version of yahoo-group-archiver is on the archiveteam github as of yet.

[17:12] == shadows [webchat@mtrlpq4709w-lp140-02-65-93-224-88.dsl.bell.ca] has joined #yahoosucks

[17:13] <shadows> Hello? I came here following getting linked to the Yahoo Groups Archiving webform. I am the administrator of a restricted-access Yahoo group.

[17:14] <shadows> (Also, omg, irc, I haven't done this in like 20 years.)

[17:14] == tonsofpcs [~mythbuntu@cpe-67-251-117-244.stny.res.rr.com] has joined #yahoosucks

[17:15] == britmob [~maxmo@pool-108-18-219-231.washdc.fios.verizon.net] has quit [Ping timeout: 252 seconds]

[17:18] <tonsofpcs> can I run a warrior 'against' yahoo groups?

[17:19] <shadows> Hi! Sorry, this is my first time here and I haven't done irc in 20 years. I came here following a link on a web form about archiving Yahoo groups.

[17:19] <@markedL> tonsofpcs : yes, but not yet, warrior part will start running around Oct 29, they want to wait for the data to be frozen 

[17:20] <@markedL> shadows : welcome , some of the admins pop-in and out because everyone's in different timezones 

[17:20] <tonsofpcs> markedL: cool, thanks. I'll keep 'choice' running.

[17:21] <shadows> Hi markedL! I came here following being linked to the archive team web form, which  contained the note "This form should not be used for private groups that need administrator approval for new members. If you're the  administrator of such a group and want it to be archived, drop by on  IRC; "

[17:21] <shadows> I am the administrator of such a group. So here I am. :-D

[17:21] <tonsofpcs> I'm not active in any yahoo groups anymore but I imagine many of them  are seeing an uptick in posts discussing how to deal with this haha

[17:22] <@markedL> shadows : they have some python code that works on restricted groups, the part that they can't do without help is the join

[17:22] <shadows> Is there someone I should email? How does this work?

[17:23] <@markedL> @betamax , I've seen send a join request to be added to a group and that was that 

[17:23] <@markedL> if you can wait for them to show up, that'd be easiest 

[17:23] <@markedL> or leave the name of the group and he'll send a join request when he gets to it 

[17:24] <@markedL> if you have to go

[17:24] <@betamax> eek, I've been very busy today, sorry everyone

[17:24] <shadows> Oh hi!

[17:24] <@betamax> (and I can't stay long, will hopefully have more time tommorow)

[17:24] <shadows> Okay, the group is RatBoat

[17:24] <shadows> A request to join it will go to me.

[17:25] <shadows> There's no hurry; we have until December 14th. :-P